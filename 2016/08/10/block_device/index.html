<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('http://yoursite.com').hostname,
    root: '/',
    scheme: 'Muse',
    version: '7.6.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":true,"preload":true},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta name="description" content="HardwareWhy use 4K device 4-KB native (4Kn) HDDs* The 4Kn HDD directly maps 4-KB logical sectors (or blocks) to the 4-KB physical sectors. 512-byte emulation (512e) HDDs* The 512e HDD transparently tr">
<meta property="og:type" content="article">
<meta property="og:title" content="The block device">
<meta property="og:url" content="http://yoursite.com/2016/08/10/block_device/index.html">
<meta property="og:site_name" content="b946c5a0bf547c89">
<meta property="og:description" content="HardwareWhy use 4K device 4-KB native (4Kn) HDDs* The 4Kn HDD directly maps 4-KB logical sectors (or blocks) to the 4-KB physical sectors. 512-byte emulation (512e) HDDs* The 512e HDD transparently tr">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://yoursite.com/img/GUID_Partition_Table_Scheme.png">
<meta property="og:image" content="http://images.anandtech.com/reviews/storage/Intel/34nmSSD/Review/garbagecollection.png">
<meta property="og:image" content="http://yoursite.com/img/hp-trim-support.png">
<meta property="article:published_time" content="2016-08-09T16:04:26.000Z">
<meta property="article:modified_time" content="2020-01-23T05:15:33.000Z">
<meta property="article:author" content="Ginger">
<meta property="article:tag" content="block">
<meta property="article:tag" content="schdule">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/img/GUID_Partition_Table_Scheme.png">

<link rel="canonical" href="http://yoursite.com/2016/08/10/block_device/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>The block device | b946c5a0bf547c89</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">b946c5a0bf547c89</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">My Silent Hill</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="Searching..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/08/10/block_device/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/img/logo-4-blog.png">
      <meta itemprop="name" content="Ginger">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="b946c5a0bf547c89">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          The block device
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2016-08-10 00:04:26" itemprop="dateCreated datePublished" datetime="2016-08-10T00:04:26+08:00">2016-08-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-01-23 13:15:33" itemprop="dateModified" datetime="2020-01-23T13:15:33+08:00">2020-01-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/scsi/" itemprop="url" rel="index">
                    <span itemprop="name">scsi</span>
                  </a>
                </span>
            </span>

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2016/08/10/block_device/#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2016/08/10/block_device/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>48k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>44 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h3 id="Hardware"><a href="#Hardware" class="headerlink" title="Hardware"></a>Hardware</h3><h4 id="Why-use-4K-device"><a href="#Why-use-4K-device" class="headerlink" title="Why use 4K device"></a>Why use 4K device</h4><ul>
<li>4-KB native (4Kn) HDDs<pre><code>* The 4Kn HDD directly maps 4-KB logical sectors (or blocks) to the 4-KB physical sectors.</code></pre></li>
<li>512-byte emulation (512e) HDDs<pre><code>* The 512e HDD transparently translates 512-byte logical block I/O requests into 4-KB physical sector operations. Each physical sector contains eight logical blocks.</code></pre></li>
</ul>
<a id="more"></a>

<p><a href="https://www.thomas-krenn.com/en/wiki/Advanced_Sector_Format_of_Block_Devices" target="_blank" rel="noopener">512e Read Operations</a><br>Read operations are very simple compared to write operations:<br>The host would like to read a 512-byte block.<br>The controller loads the complete 4KB sector containing the requested 512-byte block.<br>The controller extracts the data from the 512-byte block and delivers it in the corresponding format to the host.</p>
<p>512e Write operations use the “read-modify-write” method:<br>The host would like to write a 512-byte block.<br>The controller selects a suitable 4KB sector and loads it completely. (read)<br>The controller modifies 512 bytes in the 4KB sector. (modify)<br>The controller writes the modified 4KB sector to the hard drive. (write)</p>
<p>Compatibility<br>In order to keep performance constant, it is necessary that partitions on 512e hard drives be properly aligned (see also Partition Alignment) so that a 4KB sector contains exactly eight 512-byte blocks. Newer operating systems already correctly align the partitions (Windows &gt; Vista SP1; Linux &gt; 2.6.31 (fdisk &gt; 1.2.3))[1]. With the correct alignment, write operations can be optimally cached by the hard drive controller, which optimizes performance.</p>
<p>In <a href="https://lwn.net/Articles/322777" target="_blank" rel="noopener">This</a>, more details and add new one,the preamble</p>
<ul>
<li>Synchronization/Data Address Mark (Sync/DAM)<pre><code>* The Sync/DAM field indicates the beginning of the sector and identifies the sector’s number, location, and status.</code></pre></li>
<li>User data<pre><code>* The User data field contains actual stored data.</code></pre></li>
<li>Error correcting code (ECC)<pre><code>* The ECC field contains error-correcting code that is used to recover user data that mightbe damaged during the read or write operation.</code></pre></li>
<li>Gap<pre><code>* The Gap field is used to separate sectors from each other.</code></pre></li>
<li>Physical sector<pre><code>* Physical sector is the minimum amount of data that the HDD can read from or write to the physical media in a single I/O operation. For Advanced Format HDDs, the physical sector size is 4 KB.</code></pre></li>
<li>Logical sector<pre><code>* Logical sector is the addressable logical block, which is the minimum amount of data that the HDD can address. This amount is also the minimum amount of data that the host system can deliver to or request from the HDD in a single I/O operation. Advanced Format HDDs support 512-bytes and 4-KB logical sector sizes.</code></pre></li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">------------------------------------------</span><br><span class="line">|P|D|  Data Bytes(512/4096Bytes  | ECC |G|</span><br><span class="line">------------------------------------------</span><br><span class="line">P= Preamble</span><br><span class="line">D= Data sync mark</span><br><span class="line">ECC= Error Correcting Code</span><br><span class="line">G= Inter Sector Gap</span><br></pre></td></tr></table></figure>
<p>I think the OS kernel could not recognise ECC/G/P/D and no need to know them, maybe driver will know them. it ‘s the hardware design<br>In hardware that means there is ECC to check hardware read/write signals.</p>
<p>long-data-sector (512,520,528,4096,4112,4160,4224) will show size in logic sector</p>
<h4 id="mpt3sas-mpt2sas-driver-parameter"><a href="#mpt3sas-mpt2sas-driver-parameter" class="headerlink" title="mpt3sas/mpt2sas driver parameter"></a>mpt3sas/mpt2sas driver parameter</h4><p>parm: command_retry_count: Device discovery TUR command retry count: (default=144) (int)<br>retry count default was 144, it ‘s too large</p>
<p>parm: max_queue_depth: max controller queue depth (int) </p>
<p>The Linux “scatter/gather” table size needs to be large enough to allow IO_SIZE IO, if possible. For most drivers, this typically requires a “sg_tablesize” value of 256 or greater for 4MB IO. Different vendors have different defaults for this parameter, and may require a modprobe.conf entry to increase the value. The QLogic driver defaults to a value of 1024. For Emulex, a modeprobe.conf entry needs to be added to increase the value to 256 or greater, such as:<br>options lpfc lpfc_sg_seg_cnt=256</p>
<p>#The LSI SAS driver, “mpt2sas”, uses the parameter named “max_sgl_entries” to control this value.<br>#Its maximum value in RHEL 6.x currently only 128<br>#options mpt2sas max_sgl_entries=256<br>#Try to upgrade to upgrade mpt3sas 27.00.01.00<br>LSI 9300-8e could not modify from mpt3sas 27.00.01.00, I have not LSI 9400-8e to test</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ lspci | grep 2308</span><br><span class="line">01:00.0 Serial Attached SCSI controller: LSI Logic / Symbios Logic SAS2308 PCI-Express Fusion-MPT SAS-2 (rev 05)</span><br><span class="line">$ cat /sys/devices/pci0000:00/0000:00:02.1/0000:01:00.0/host1/scsi_host/host1/sg_tablesize</span><br><span class="line">128</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> 256 &gt; /sys/devices/pci0000:00/0000:00:02.1/0000:01:00.0/host1/scsi_host/host1/sg_tablesize</span><br><span class="line"><span class="built_in">echo</span>: write error: Input/output error</span><br></pre></td></tr></table></figure>

<h4 id="mpt3sas-driver-install"><a href="#mpt3sas-driver-install" class="headerlink" title="mpt3sas driver install"></a>mpt3sas driver install</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#compile to local</span><br><span class="line">$ make -j4 CONFIG_DEBUG_INFO&#x3D;1 -C &#x2F;lib&#x2F;modules&#x2F;$(uname -r)&#x2F;build M&#x3D;&#x2F;sources&#x2F;tools&#x2F;dell&#x2F;lsi-9300-8e&#x2F;mpt3sas</span><br><span class="line"></span><br><span class="line">#compile to local kernel </span><br><span class="line">$ make -j4 CONFIG_DEBUG_INFO&#x3D;1 -C &#x2F;lib&#x2F;modules&#x2F;$(uname -r)&#x2F;build M&#x3D;&#x2F;sources&#x2F;tools&#x2F;dell&#x2F;lsi-9300-8e&#x2F;mpt3sas modules_install</span><br></pre></td></tr></table></figure>
<h5 id="Driver-Build-Instructions"><a href="#Driver-Build-Instructions" class="headerlink" title="Driver Build Instructions"></a><a href="//docs.broadcom.com/docs-and-downloads/host-bus-adapters/host-bus-adapters-common-files/README_FOR_LinuxMPT_SAS2_RHEL5_SLES10_P9-zip.pdf" target="_blank" rel="noopener">Driver Build Instructions</a></h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line">The following examples show how to configure and build the LSI Fusion-MPT driver(s) as</span><br><span class="line">kernel modules. In this example the driver version is (01.255.06.00-1). Here is the procedure</span><br><span class="line">to build the drivers out of kernel tree:</span><br><span class="line"> Extract the packaging from Linux system:</span><br><span class="line"> <span class="comment"># tar -zxvf mpt2sas-release.tar.gz</span></span><br><span class="line"> <span class="comment"># tar -zxvf mpt2sas-01.255.06.00.tar.gz</span></span><br><span class="line"> <span class="comment"># cd mpt2sas</span></span><br><span class="line"> <span class="comment"># ./compile</span></span><br><span class="line"> <span class="comment"># ./load</span></span><br><span class="line">Alternatively, here is the procedure to build driver <span class="keyword">in</span> kernel tree</span><br><span class="line">1. From the /usr/src/linux directory, ensure a clean kernel <span class="built_in">source</span> tree by executing the</span><br><span class="line">following <span class="built_in">command</span>:</span><br><span class="line"> <span class="comment"># make mrproper</span></span><br><span class="line">2. From the /usr/src/linux directory, run the normal kernel configuration routine:</span><br><span class="line"> <span class="comment"># make oldconfig</span></span><br><span class="line"> or:</span><br><span class="line"> <span class="comment"># make config</span></span><br><span class="line"> or:</span><br><span class="line"> <span class="comment"># make menuconfig</span></span><br><span class="line"> or:</span><br><span class="line"> <span class="comment"># make xconfig</span></span><br><span class="line">3. Here are the directions <span class="keyword">for</span> finding the entry <span class="keyword">in</span> menuconfig ncurses display</span><br><span class="line"> Device Drivers ---&gt;</span><br><span class="line"> SCSI device support ---&gt;</span><br><span class="line"> SCSI low-level drivers ---&gt;</span><br><span class="line"> &lt;M&gt; LSI MPT Fusion SAS 2.0 Device Driver</span><br><span class="line"> (128) LSI MPT Fusion Max number of SG Entries (16 - 128) (NEW)</span><br><span class="line"> [*] LSI MPT Fusion logging facility</span><br><span class="line"> On the sub menu, select the <span class="string">"LSI MPT Fusion SAS 2.0 Device Driver"</span> line,</span><br><span class="line"> and <span class="keyword">then</span> enter <span class="string">"m"</span> to configure <span class="keyword">for</span> building this support as a module.</span><br><span class="line"> (Alternatively, you can enter <span class="string">"y"</span> to have this support built</span><br><span class="line"> into the kernel.)</span><br><span class="line"> NOTES:</span><br><span class="line"> o CONFIG_SCSI_MPT2SAS_MAX_SGE: This option allows you to specify the</span><br><span class="line"> maximum number of scatter-gather entries per I/O. The driver default</span><br><span class="line"> is 128, <span class="built_in">which</span> matches MAX_HW_SEGMENTS. However, it may decreased</span><br><span class="line"> down to 16. Decreasing this parameter will reduce memory requirements</span><br><span class="line"> on a per controller instance.</span><br><span class="line"> o CONFIG_SCSI_MPT2SAS_LOGGING: This turns on a logging facility.</span><br><span class="line">4. Save the kernel configuration changes. Follow any post configuration instructions, and <span class="keyword">do</span></span><br><span class="line">everything needed on your platform to rebuild the kernel. This typically includes:</span><br><span class="line"></span><br><span class="line"> <span class="comment"># make dep</span></span><br><span class="line"> and:</span><br><span class="line"> <span class="comment"># make bzImage # varies on non-Intel platforms</span></span><br><span class="line">5. Rebuild the kernel modules:</span><br><span class="line"> <span class="comment"># make modules</span></span><br><span class="line">6. Optionally, (and potentially dangerous!), <span class="keyword">do</span> everything needed on your platform to install a</span><br><span class="line">newly built kernel. (possibly temporarily, <span class="keyword">for</span> sanity testing)</span><br><span class="line"> Be careful with this step, and be sure you know what you<span class="string">'re doing!</span></span><br><span class="line"><span class="string"> It is easy to wipe out a good/stable kernel from this point forward</span></span><br><span class="line"><span class="string"> in the procedure!</span></span><br><span class="line"><span class="string">7. (Re)Install newly compiled kernel modules:</span></span><br><span class="line"><span class="string"> # make modules_install</span></span><br><span class="line"><span class="string"> The output from the last step should look something like this:</span></span><br><span class="line"><span class="string"> Installing modules under /lib/modules/2.6.30/block</span></span><br><span class="line"><span class="string"> Installing modules under /lib/modules/2.6.30/net</span></span><br><span class="line"><span class="string"> Installing modules under /lib/modules/2.6.30/ipv4</span></span><br><span class="line"><span class="string"> Installing modules under /lib/modules/2.6.30/scsi</span></span><br><span class="line"><span class="string"> Installing modules under /lib/modules/2.6.30/fs</span></span><br><span class="line"><span class="string"> Installing modules under /lib/modules/2.6.30/fs</span></span><br><span class="line"><span class="string"> Installing modules under /lib/modules/2.6.30/cdrom</span></span><br><span class="line"><span class="string"> Installing modules under /lib/modules/2.6.30/video</span></span><br><span class="line"><span class="string"> Installing modules under /lib/modules/2.6.30/net</span></span><br><span class="line"><span class="string"> Installing modules under /lib/modules/2.6.30/misc</span></span><br><span class="line"><span class="string">8. Update your /boot sector with the new System.map and bzImage, re-create your ramdisk</span></span><br><span class="line"><span class="string">image (refer to your vendor literature), and update your boot manager--i.e., lilo.conf,</span></span><br><span class="line"><span class="string">grub.conf. If you are using lilo, you must run lilo -v prior to reboot.</span></span><br><span class="line"><span class="string">9. Shut down the system:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> Example:</span></span><br><span class="line"><span class="string"> # shutdown -r now</span></span><br><span class="line"><span class="string"> and then reboot with the newly built Linux kernel</span></span><br></pre></td></tr></table></figure>

<h4 id="Qlogic-driver-setting"><a href="#Qlogic-driver-setting" class="headerlink" title="Qlogic driver setting"></a>Qlogic driver setting</h4><p>Adpater reset time e.g. Qlogic reset time<br>echo options qla2xxx ql2xextended_error_logging=1 qlport_down_retry=10 ql2xloginretrycount=10 &gt;&gt;  /etc/modprobe.d/qlogic.conf<br>Multipath check_timeout  (reduce to 10 seconds from default 60 seconds)</p>
<p>Set the max_segments for HBA driver<br>| HBA       | Module Parameter|<br>|———–|:—————:|<br>| LSI       |  max_sgl_entries|<br>| Emulex    |  lpfc_sg_seg_cnt|<br>| ib_srp    |  cmd_sg_entries |<br>| Brocade   |  bfa_io_max_sge |</p>
<p>Set max_hw_sectors_kb for HBA driver<br>| HBA       | Module Parameter|<br>|———–|:—————:|<br>| LSI       |  max_sectors    |<br>| ib_srp    |  max_sect       |<br>| Brocade   |  max_xfer_size  |</p>
<p>mpt3sas<br>max_sectors:max sectors, range 64 to 32767  default=32767 (ushort)</p>
<h4 id="SAN-controller-setting-MD3460"><a href="#SAN-controller-setting-MD3460" class="headerlink" title="SAN controller setting MD3460"></a>SAN controller setting MD3460</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">RAID 6               8+2</span><br><span class="line">segment              128K</span><br><span class="line">cache block size     32K</span><br><span class="line">cache flush          90%</span><br><span class="line">Write cache mirror   enabled</span><br><span class="line">Read cache           disabled</span><br></pre></td></tr></table></figure>

<h3 id="rebuild-feature"><a href="#rebuild-feature" class="headerlink" title="rebuild feature"></a>rebuild feature</h3><p>In May 2012, with 3.5-inch hard drive capacities reaching 4TB, the T10 working group approved including Rebuild Assist in the SCSI SBC-3 specification. In August 2013, the SATA-IO committee adopted TPR-045 (Rebuild Assist) as part of the SATA 3.2 specification.”) so with a Rebuild Assist supported RAID controller: can copy good data from a failing drive to a new drive and only need to rebuild the ‘bad’ portion, supposably resulting in quicker rebuild times</p>
<h3 id="Linux-setting"><a href="#Linux-setting" class="headerlink" title="Linux setting"></a>Linux setting</h3><h4 id="block-driver"><a href="#block-driver" class="headerlink" title="block driver"></a>block driver</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">$ $ cat /sys/block/sdX/device/state</span><br><span class="line">running</span><br><span class="line"></span><br><span class="line">$ cat /sys/block/sdz/device/queue_depth</span><br><span class="line">254</span><br><span class="line"></span><br><span class="line">$ cat /sys/block/sda/queue/nomerges </span><br><span class="line"><span class="comment">#set nomerges to 0 for HDDs or to 1 for SSDs</span></span><br><span class="line"></span><br><span class="line">$ cat /sys/block/sdd/queue/add_random </span><br><span class="line"><span class="comment">#The default value is 1. Set add_random=0 for SSDs because random entropy pool does not optimize SSD performance</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># check scsi state</span></span><br><span class="line">$ cat /sys/block/sdX/device/state</span><br><span class="line">running</span><br><span class="line"></span><br><span class="line">$ <span class="built_in">echo</span> 30 &gt; /sys/block/sdX/device/timeout</span><br><span class="line"><span class="comment"># I don 't think set the value too long</span></span><br><span class="line"></span><br><span class="line">$ cat /etc/udev/rules.d/50-udev.rules</span><br><span class="line">ACTION==<span class="string">"add"</span>, SUBSYSTEM==<span class="string">"scsi"</span> , SYSFS&#123;<span class="built_in">type</span>&#125;==<span class="string">"0|7|14"</span>, RUN+=<span class="string">"/bin/sh -c 'echo 30 &gt; /sys/block/%k/device/timeout'"</span> </span><br><span class="line"></span><br><span class="line"><span class="comment">### another exapmle</span></span><br><span class="line">KERNEL==<span class="string">"sdc5"</span>, OWNER=<span class="string">"student"</span>, GROUP=<span class="string">"student"</span>, MODE=<span class="string">"0600"</span></span><br><span class="line">ACTION==<span class="string">"add"</span>, KERNEL==<span class="string">"sd*"</span>, SYSFS==<span class="string">"4317210A2880EF89"</span>, SYMLINK+=<span class="string">"fedora%n"</span></span><br><span class="line">ACTION==<span class="string">"add"</span>, KERNEL==<span class="string">"sdb[1-9]"</span>, RUN=<span class="string">"/usr/bin/wall  SCSI DEVICE ADDED"</span></span><br><span class="line">ACTION==<span class="string">"remove"</span>, KERNEL==<span class="string">"sdb[1-9]"</span>, RUN=<span class="string">"/usr/bin/wall SCSI DEVICE REMOVED"</span></span><br><span class="line">ACTION==<span class="string">"add"</span>, KERNEL==<span class="string">"sdb[1-9]"</span>, SYMLINK=<span class="string">"scsi%n"</span></span><br><span class="line">ACTION==<span class="string">"remove"</span>, KERNEL==<span class="string">"sdb[1-9]"</span>, SYMLINK=<span class="string">"scsi%n"</span></span><br><span class="line">ACTION==<span class="string">"add"</span>, KERNEL==<span class="string">"sd*[!0-9]"</span>, SYSFS&#123;vendor&#125;==<span class="string">"WDC WD32"</span>, RUN+=<span class="string">"/bin/sh -c 'echo 128 &gt; /sys/block/%k/queue/max_sectors_kb'"</span></span><br><span class="line">ACTION==<span class="string">"add"</span>, KERNEL==<span class="string">"sd*[!0-9]"</span>, SYSFS&#123;vendor&#125;==<span class="string">"WDC WD32"</span>, RUN+=<span class="string">"/usr/bin/wall /sys/block/%k/queue/max_sectors_kb set to 128"</span></span><br></pre></td></tr></table></figure>

<h4 id="block-driver-2"><a href="#block-driver-2" class="headerlink" title="block driver 2"></a><a href="https://library.netapp.com/ecmdocs/ECMP12404601/html/GUID-436F7286-AD26-4A8D-A2D1-2BC8B5CFC023.html" target="_blank" rel="noopener">block driver 2</a></h4><p><a href="https://access.redhat.com/solutions/43861" target="_blank" rel="noopener">redhat doc</a></p>
<ul>
<li>max_hw_sectors_kb (RO) - This parameter sets the maximum number of kilobytes that the hardware allows for request.<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># ubuntu 18.04 server, sas 10TB 512e HDD</span><br><span class="line">$ cat &#x2F;sys&#x2F;block&#x2F;sda&#x2F;queue&#x2F;max_hw_sectors_kb </span><br><span class="line">16383</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>max_sectors_kb = avgrq-sz(iostat)</p>
<ul>
<li><p><a href="https://access.redhat.com/solutions/2150101" target="_blank" rel="noopener">max_sectors_kb</a> (RW) - This parameter sets the maximum number of kilobytes that the block layer allows for a file system request. The value of this parameter must be less than or equal to the maximum size allowed by the hardware. The kernel also places an upper bound on this value with the BLK_DEF_MAX_SECTORS macro. This value varies from distribution to distribution, for example, it is 1024 on RHEL 6.3, 2048 on SLES 11 SP2.</p>
<pre><code>* This specifies the maximum I/O size that the host will issue to the target storage. linxu 4.1x default value was 1280, Typically it is 512KiB (512 Bytes,1024 sectors, 4KN, 1024 sectors means 4096KiB)</code></pre><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cat /sys/block/sda/queue/max_sectors_kb </span><br><span class="line">1280</span><br></pre></td></tr></table></figure>
</li>
<li><p>max_segments (RO) - This parameter enables low level driver to set an upper limit on the number of hardware data segments in a request. In the HBA drivers, this is also known as sg_tablesize.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cat /sys/block/sda/queue/max_segments</span><br><span class="line">128</span><br></pre></td></tr></table></figure>
</li>
<li><p>max_segment_size (RO) - This parameter enables low level driver to set an upper limit on the size of each data segment in an I/O request in bytes. If clustering is enabled on the low level driver it is set to 65536 or it is set to system PAGE_SIZE by default, which is typically 4K. The maximum I/O size is determined by the following:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cat /sys/block/sda/queue/max_segment_size </span><br><span class="line">65536</span><br></pre></td></tr></table></figure>
<p>MAX_IO_SIZE_KB = MIN(max_sectors_kb, (max_segment_size * max_segments)/1024)<br>1280 KB       = MIN(1280, (65536*128)/1024) = MIN(1280, 8192)</p>
</li>
</ul>
<p>In this command, PAGE_SIZE is architecture independent. It is 4096 for x86_64.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#or you could set it from 1280 to 8192</span><br><span class="line">$ echo 8192 &gt; max_sectors_kb</span><br></pre></td></tr></table></figure>

<ul>
<li><p>physical_block_size</p>
<ul>
<li>Smallest internal unit on which the device can operate<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 4KN HDD, there is no 512n in the large capacity HDD</span></span><br><span class="line">$ cat /sys/block/sdj/queue/physical_block_size</span><br><span class="line">4096</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>logical_block_size</p>
<ul>
<li>Used externally to address a location on the device<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 4KN</span></span><br><span class="line">$ cat /sys/block/sdj/queue/logical_block_size</span><br><span class="line">4096</span><br><span class="line"></span><br><span class="line"><span class="comment"># 512e</span></span><br><span class="line">$ cat /sys/block/sdi/queue/logical_block_size</span><br><span class="line">512</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>alignment_offset</p>
<ul>
<li>The number of bytes that the beginning of the Linux block device (partition/MD/LVM device) is offset from the underlying physical alignment<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cat /sys/block/sdj/alignment_offset</span><br><span class="line">0</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>minimum_io_size</p>
<ul>
<li>The device’s preferred minimum unit for random I/O</li>
<li>The minimum_io_size and optimal_io_size values for /dev/sdX devices are retrieved by the kernel by inquiring the storage vendor-provided I/O Limits within the device VPD pages.<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cat /sys/block/sdj/queue/minimum_io_size</span><br><span class="line">4096</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p><a href="http://fibrevillage.com/storage/563-storage-i-o-alignment-and-size" target="_blank" rel="noopener">optimal_io_size</a></p>
<ul>
<li>The device’s preferred unit for streaming I/O<ul>
<li>Only one layer in the I/O stack should adjust for a non-zero alignment_offset; once a layer adjusts accordingly, it will export a device with an alignment_offset of zero. </li>
<li>A striped Device Mapper (DM) device created with LVM must export a minimum_io_size and optimal_io_size relative to the stripe count (number of disks) and user-provided chunk size.<br>Note<br>Red Hat Enterprise Linux 7 cannot distinguish between devices that don’t provide I/O hints and those that do so with alignment_offset= 0 and optimal _io_size= 0 . Such a device might be a single SAS 4K device; as such, at worst 1MB of space is lost at the start of the disk.</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cat /sys/block/sdj/queue/optimal_io_size</span><br><span class="line">0</span><br></pre></td></tr></table></figure>
<p>If wanting to change the optimal_io_size on a dm(multipath) device add parameter max_sectors_kb to the /etc/multipath.conf file for the specific storage array (and change the underlying sd devices using an udev rule).</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># I don 't know why only zero in [1] and [2] location</span></span><br><span class="line"></span><br><span class="line">$ sg_inq -p 0xb0 /dev/sdacn</span><br><span class="line">VPD INQUIRY: Block limits page (SBC)</span><br><span class="line">  Optimal transfer length granularity: 1 blocks   &lt;&lt; [1] block-size x this field = minimal_io_size, block-size defined <span class="keyword">in</span> READCAP <span class="built_in">command</span> below.</span><br><span class="line">  Maximum transfer length: 8192 blocks</span><br><span class="line">  Optimal transfer length: 8192 blocks            &lt;&lt; [2] block-size x this field = optimal_io_size</span><br><span class="line">  Maximum prefetch, xdread, xdwrite transfer length: 0 blocks</span><br><span class="line"></span><br><span class="line">$ sg_readcap -16 /dev/sdacn</span><br><span class="line">Read Capacity results:</span><br><span class="line">   Protection: prot_en=0, p_type=0, p_i_exponent=0</span><br><span class="line">   Thin provisioning: tpe=0, tprz=0</span><br><span class="line">   Last logical block address=4194303 (0x3fffff), Number of logical blocks=4194304</span><br><span class="line">   Logical block length=512 bytes                &lt;&lt; [3] this is block size (length), multiplier <span class="keyword">for</span> above fields.</span><br><span class="line">   Logical blocks per physical block exponent=0</span><br><span class="line">   Lowest aligned logical block address=0</span><br><span class="line">Hence:</span><br><span class="line">   Device size: 2147483648 bytes, 2048.0 MiB, 2.15 GB</span><br><span class="line"></span><br><span class="line">$ grep -v <span class="string">"zz"</span> /sys/block/sdacn/queue/*io_size</span><br><span class="line">/sys/block/sdacn/queue/minimum_io_size:512       &lt;&lt; [1] 1 block     x [3] 512-bytes/block =     512 bytes.</span><br><span class="line">/sys/block/sdacn/queue/optimal_io_size:4194304   &lt;&lt; [2] 8192 blocks x [3] 512-bytes/block = 4194034 bytes.</span><br></pre></td></tr></table></figure>
<p>This does hint to the fact that it is possible to see different optimal_io_size for the same LUN across different access paths. This can happen (from storage controller configuration issues, manual changes (echo) or a trigger of udev rules), which could cause an exceptionally high optimal_io_size for the dm(multipath) device or paths which will not function. If this is seen, and the sg_readcap and sg_inq is lining up with what is in /sys, it is likely due to a storage controller configuration issue, and the system’s SAN vendor should be contacted for analysis. Below is an example of what this would look like, noting that 4278190080 is the LCM (least common multiple) of 4177920 and 16777216</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ multipath -ll disk1</span><br><span class="line">disk1 (wwid_entry_omitted) dm-108 3PARdata,VV</span><br><span class="line">size=80G features=<span class="string">'1 queue_if_no_path'</span> hwhandler=<span class="string">'1 alua'</span> wp=rw</span><br><span class="line">`-+- policy=<span class="string">'round-robin 0'</span> prio=1 status=active</span><br><span class="line">  |- 0:0:0:152 sdcg 69:64   active ready running</span><br><span class="line">  |- 1:0:0:152 sdjc 8:352   active ready running</span><br><span class="line">  |- 0:0:1:152 sdfr 130:208 active ready running</span><br><span class="line">  `- 1:0:1:152 sdmn 69:496  active ready running</span><br><span class="line"></span><br><span class="line">$ <span class="keyword">for</span> i <span class="keyword">in</span> dm-108 sdcg sdjc sdfr sdmn ; <span class="keyword">do</span> cat /sys/block/<span class="variable">$i</span>/queue/optimal_io_size ; <span class="keyword">done</span></span><br><span class="line">4278190080     &lt;&lt; LCM of 16777216 and 4177920</span><br><span class="line">16777216       &lt;&lt; Optimal transfer length: 32768 blocks x Logical block length=512 bytes</span><br><span class="line">16777216       &lt;&lt; Optimal transfer length: 32768 blocks x Logical block length=512 bytes</span><br><span class="line">4177920        &lt;&lt; Optimal transfer length: 8160 blocks x Logical block length=512 bytes</span><br><span class="line">4177920        &lt;&lt; Optimal transfer length: 8160 blocks x Logical block length=512 bytes</span><br></pre></td></tr></table></figure>

<h5 id="parted-alignment"><a href="#parted-alignment" class="headerlink" title="parted alignment"></a>parted alignment</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ parted /dev/sdX <span class="string">'unit s print'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Is the partition align ?</span></span><br><span class="line">$ parted /dev/sdX align-check optimal 1</span><br><span class="line">1 aligned</span><br><span class="line"></span><br><span class="line"><span class="comment">#auto align</span></span><br><span class="line">$ parted -a optimal /dev/sdX mkpart primary 0% xxTB</span><br><span class="line"><span class="comment"># cylinder,none,minimal,optimal</span></span><br></pre></td></tr></table></figure>
<p>GUID Partition Table Scheme<br><img src="/img/GUID_Partition_Table_Scheme.png" alt=""></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">-------------</span><br><span class="line">LBA0 prrotective MBR</span><br><span class="line">-------------</span><br><span class="line">LBA1 Primary GPT header</span><br><span class="line">-------------</span><br><span class="line">LBA2 Entry1|Entry2|Entry3|Entry4</span><br><span class="line">-------------</span><br><span class="line">LBA3 Entries 5-128</span><br><span class="line">------------</span><br><span class="line">LBA34  Partirion1,2..</span><br><span class="line">LBA-34 remaining Partitions</span><br><span class="line">------------</span><br><span class="line">LBA-33  Entry1|Entry2|entry3|Entry4</span><br><span class="line">------------</span><br><span class="line">LBA-2   Entries 5-128</span><br><span class="line">------------</span><br><span class="line">LBA-1   Secondary GPT Header</span><br><span class="line">----</span><br></pre></td></tr></table></figure>

<h5 id="Hot-plugin-the-scsi-device"><a href="#Hot-plugin-the-scsi-device" class="headerlink" title="Hot plugin the scsi device"></a>Hot plugin the scsi device</h5><p>What is h c t l<br>          h == hostadapter id (first one being 0)<br>          c == SCSI channel on hostadapter (first one being 0)<br>          t == ID (target)<br>          l == LUN (first one being 0)<br>Generic SCSI devices can also be accessed via the bsg driver in Linux. By default, the bsg driver’s device node names  are  of  the  form ‘/dev/bsg/H:C:T:L’.  So,  for example, the SCSI device shown by this utility on a line starting with the tuple ‘6:0:1:2’ could be accessed via the bsg driver with the ‘/dev/bsg/6:0:1:2’ device node name.</p>
<h5 id="Add-the-scsi-device"><a href="#Add-the-scsi-device" class="headerlink" title="Add the scsi device"></a>Add the scsi device</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;- - -&quot; &gt; &#x2F;sys&#x2F;class&#x2F;scsi_host&#x2F;host&lt;h&gt;&#x2F;scan</span><br><span class="line">echo &quot;c t l&quot; &gt;  &#x2F;sys&#x2F;class&#x2F;scsi_host&#x2F;host&lt;h&gt;&#x2F;scan</span><br></pre></td></tr></table></figure>

<h5 id="Refresh-the-scsi-device"><a href="#Refresh-the-scsi-device" class="headerlink" title="Refresh the scsi device"></a>Refresh the scsi device</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> 1 &gt; /sys/block/sdau/device/rescan</span><br><span class="line"><span class="built_in">echo</span> 1 &gt; /sys/class/scsi_device/h:c:t:l/device/rescan</span><br></pre></td></tr></table></figure>

<h5 id="Remove-the-scsi-device"><a href="#Remove-the-scsi-device" class="headerlink" title="Remove the scsi device"></a>Remove the scsi device</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> 1 &gt; /sys/class/scsi_device/h:c:t:l/device/delete</span><br><span class="line"><span class="built_in">echo</span> 1 &gt; /sys/block/&lt;dev&gt;/device/delete</span><br></pre></td></tr></table></figure>

<h4 id="IO-schdule"><a href="#IO-schdule" class="headerlink" title="IO schdule"></a>IO schdule</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">schdule = deadline</span><br><span class="line">nr_request = 1024</span><br><span class="line">max_sector_kb = 1024</span><br><span class="line">read_ahead_kb = 8192</span><br><span class="line">rq_affinity = 2</span><br><span class="line"><span class="comment"># For storage configurations that need to maximize distribution of completion processing setting this option to '2' forces the completion to run on the requesting cpu (bypassing the "group" aggregation logic).</span></span><br><span class="line"></span><br><span class="line">vm.dirty_ratio = 40</span><br><span class="line"><span class="comment"># dirty_ratio     "Dirty" memory is that waiting to be written to disk. dirty_ratio is the number of memory pages at which a process will start writing out dirty data, expressed as a percentage out of the total free and reclaimable pages. A default of 20 is reasonable. Increase to 40 to improve throughput, decrease it to 5 to 10 to improve latency, even lower on systems with a lot of memory.</span></span><br><span class="line"></span><br><span class="line">vm.dirty_background_ratio = 20</span><br><span class="line"><span class="comment"># dirty_background_ratio  Similar, but this is the number of memory pages at which the kernel background flusher thread will start writing out dirty data, expressed as a percentage out of the total free and reclaimable pages. Set this lower than dirty_ratio, dirty_ratio/2 makes sense and is what the kernel does by default. This page shows that dirty_ratio has the greater effect. Tune dirty_ratio for performance, then set dirty_background_ratio to half that value.</span></span><br><span class="line"></span><br><span class="line">vm.vfs_cache_pressure = 50</span><br><span class="line">This sets the <span class="string">"pressure"</span> or the importance the kernel places upon reclaiming memory used <span class="keyword">for</span> caching directory and inode objects. The default of 100 or relative <span class="string">"fair"</span> is appropriate <span class="keyword">for</span> compute servers. Set to lower than 100 <span class="keyword">for</span> file servers on <span class="built_in">which</span> the cache should be a priority. Set higher, maybe 500 to 1000, <span class="keyword">for</span> interactive systems.</span><br><span class="line"></span><br><span class="line">overcommit_memory       Allows <span class="keyword">for</span> poorly designed programs <span class="built_in">which</span> malloc() huge amounts of memory <span class="string">"just in case"</span> but never really use it. Set this to 0 (disabled) unless you really need it.</span><br></pre></td></tr></table></figure>

<h4 id="deadline-parameters"><a href="#deadline-parameters" class="headerlink" title="deadline parameters"></a><a href="https://cromwell-intl.com/open-source/performance-tuning/disks.html" target="_blank" rel="noopener">deadline parameters</a></h4><p>fifo_batch      Number of read or write operations to issue in one batch.  Lower values may further reduce latency. Higher values can increase throughput on rotating mechanical disks, but at the cost of worse latency. You selected the deadline scheduler to limit latency, so you probably don’t want to increase this, at least not by very much.</p>
<p>read_expire     Number of milliseconds within which a read request should be served. Reduce this from the default of 500 to 100 on a system with interactive users.</p>
<p>rite_expire     Number of milliseconds within which a write request should be served.<br>Leave at default of 5000, let write operations be done asynchronously in the background unless your specialized application uses many synchronous writes.</p>
<p>writes_starved  Number read batches that can be processed before handling a write batch. Increase this from default of 2 to give higher priority to read operations.</p>
<p>nr_requests     Maximum number of read and write requests that can be queued at one time before the next process requesting a read or write is put to sleep. Default value of 128 means 128 read requests and 128 write requests can be queued at once. Larger values may increase throughput for workloads writing many small files, smaller values increase throughput with larger I/O operations. You could decrease this if you are using latency-sensitive applications, but then you shouldn’t be using NOOP if latency is sensitive!</p>
<p>read_ahead_kb   Number of kilobytes the kernel will read ahead during a sequential read operation. 128 kbytes by default, if the disk is used with LVM the device mapper may benefit from a higher value. If your workload does a lot of large streaming reads, larger values may improve performance.</p>
<p>max_sectors_kb  Maximum allowed size of an I/O request in kilobytes, which must be within these bounds:<br>Min value = max(1, logical_block_size/1024)<br>Max value = max_hw_sectors_kb</p>
<p>rotational      Should be 0 (no) for solid-state disks, but some do not correctly report their status to the kernel. If incorrectly set to 1 for an SSD, set it to 0 to disable unneeded scheduler logic meant to reduce number of seeks.</p>
<h3 id="scsi-driver-error-handaling-EH"><a href="#scsi-driver-error-handaling-EH" class="headerlink" title="scsi_driver error handaling (EH)"></a>scsi_driver error handaling (EH)</h3><p>scsi driver error Handaling (EH) timeout – eh_timeout (from default 10 second to 5 seconds)<br>HBA reset time - eh_deadline (from disable/0 to 5 seconds, default was off)</p>
<p>The SCSI error handling (EH) mechanism attempts to perform error recovery on failed SCSI devices. The SCSI host object eh_deadline parameter enables you to configure the maximum amount of time for the recovery. After the configured time expires, SCSI EH stops and resets the entire host bus adapter (HBA).</p>
<h3 id="iostat"><a href="#iostat" class="headerlink" title="iostat"></a><a href="https://stackoverflow.com/questions/4458183/how-the-util-of-iostat-is-computed" target="_blank" rel="noopener">iostat</a></h3><p>%util = blkio.ticks / deltams * 100%</p>
<p>deltams is the time elapsed since last snapshot in ms. It uses CPU stats from /proc/stat presumably because it gives better results than to rely on system time, but I don’t know for sure. (Side note: for some reason the times are divided by HZ, while the documentation states it’s in USER_HZ, I don’t understand that.)<br>blkio.ticks is “# of milliseconds spent doing I/Os”, from /proc/diskstats docs:</p>
<p>Field  9 – # of I/Os currently in progress<br>  The only field that should go to zero. Incremented as requests are<br>  given to appropriate struct request_queue and decremented as they finish.<br>Field 10 – # of milliseconds spent doing I/Os<br>  This field increases so long as field 9 is nonzero.</p>
<p>struct ext_disk_stats *xds<br>xds-&gt;util</p>
<p>Hypothesis:<br>Simple understand about util% =  IO time/the time(the clock) , if IO time &gt;= the time, the utils = 100%(in 1s), else, that means some times there is no IO ops in this second<br>Why no ops in this sec ? maybe something hang, maybe just no any IO loading</p>
<p>In SAS arch, there are multiple lane/phy in it, if single lane/phy has full IO loading, the util% will reach 100%<br>Yes the device could be parallel, there are a lot of lane/phy are free, but the single lane or phy has full. I think the util% was right</p>
<ol>
<li>The single path(resource) was full (nvme,sas ssd)</li>
<li>If the block device ‘s performance is infinity,  All of CPU/Mem/NIC speed behind it. the bottle-neck not in the block device. some of syscall cause the util%=100% too</li>
<li>Could the util% show the device are busy ? That right, util% is not enough, Could the iostat show the device are busy ? Yes, it can<br>You can watch the await and util%, you could know the device busy or free. it ‘s so easy</li>
</ol>
<p>“iostat was not correct, it just show the wrong value”. That ‘s alarmist for iostat ,and it ‘s so funny</p>
<p>This guy analyzed the code, but it ‘s not enough, he was not understand the iostat output.<br>The <a href="https://bean-li.github.io/dive-into-iostat/" target="_blank" rel="noopener">example</a> is good.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ID      Time    Ops                                  in_flight  stamp   stamp_delta           io_ticks            time_in_queue</span><br><span class="line">0       100     new request in the queue                0       0       no need caculate          0                 0</span><br><span class="line">1       100.10  another request go to the queue         1       100     100.10-100 &#x3D; 0.1        0.1                 0.1</span><br><span class="line">2       101.20  finish the first request                2       100.10  101.20-100.10 &#x3D; 1.1     1.2(1.1+0.1)        0.1+1.1*2 (total 2x io requests) &#x3D; 2.3</span><br><span class="line">3       103.60  finish the second request               1       101.20  103.60-101.20 &#x3D; 2.4     3.6                 2.3+2.4*1&#x3D;4.7</span><br><span class="line">4       153.60  The third request go to the queue       0       103.60  no need caculate        3.6                 4.7</span><br><span class="line">5       153.90  Finish the third request                1       153.60  153.90 - 153.60 &#x3D; 0.3   3.9                 4.7+0.3 * 1&#x3D; 5</span><br></pre></td></tr></table></figure>
<p>In 53.9s, All io requests in 3.9s, the other times has no any IO in the queue.<br>io_ticks  –&gt; util %<br>time_in_queue –&gt; avgqu-sz</p>
<h3 id="Re-import-LVM"><a href="#Re-import-LVM" class="headerlink" title="Re-import LVM"></a>Re-import LVM</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ storcli64 /call/fall show</span><br><span class="line">$ storcli64 /c0/fall import</span><br><span class="line">$ vgscan</span><br><span class="line"> Reading all physical volumes.  This may take a <span class="keyword">while</span>...</span><br><span class="line">  Found volume group <span class="string">"xx"</span> using metadata <span class="built_in">type</span> lvm2</span><br><span class="line">$ vgchange -ay</span><br><span class="line">  1 logical volume(s) <span class="keyword">in</span> volume group <span class="string">"xx"</span> now active</span><br><span class="line">$ lvs</span><br><span class="line">xx_lv  xx_vg -wi<span class="_">-a</span>-----  1t</span><br><span class="line">$ lvdisplay</span><br></pre></td></tr></table></figure>

<h3 id="Advance-reformat-4Kn-SCSI-devs-to-512-Bytes-sector"><a href="#Advance-reformat-4Kn-SCSI-devs-to-512-Bytes-sector" class="headerlink" title="Advance reformat 4Kn SCSI devs to 512 Bytes sector"></a>Advance reformat 4Kn SCSI devs to 512 Bytes sector</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">$ smartctl -a -d scsi /dev/sdd</span><br><span class="line">smartctl 5.43 2012-06-30 r3573 [x86_64-linux-2.6.32-504.30.3.el6_lustre.x86_64] (<span class="built_in">local</span> build)</span><br><span class="line">Copyright (C) 2002-12 by Bruce Allen, http://smartmontools.sourceforge.net</span><br><span class="line"></span><br><span class="line">Vendor:               HGST</span><br><span class="line">Product:              HUH728080AL4200</span><br><span class="line">Revision:             A7J0</span><br><span class="line">User Capacity:        8,001,563,222,016 bytes [8.00 TB]</span><br><span class="line">Logical block size:   4096 bytes</span><br><span class="line"></span><br><span class="line">$ smartctl -a -d scsi /dev/sdc</span><br><span class="line">smartctl 5.43 2012-06-30 r3573 [x86_64-linux-2.6.32-504.30.3.el6_lustre.x86_64] (<span class="built_in">local</span> build)</span><br><span class="line">Copyright (C) 2002-12 by Bruce Allen, http://smartmontools.sourceforge.net</span><br><span class="line"></span><br><span class="line">Vendor:               HGST</span><br><span class="line">Product:              HUH728080AL4200</span><br><span class="line">Revision:             A7J0</span><br><span class="line">User Capacity:        8,001,563,222,016 bytes [8.00 TB]</span><br><span class="line">Logical block size:   512 bytes</span><br></pre></td></tr></table></figure>

<p>Update: If you have a lot of drives to format, it may take a long time with sg_format as it wait until it finished before doing the next one (with a while loop I mean). Useful tip is to use the “-e” flag with sg_format then monitor operations with sg_turs -p but it may hang you tty as well.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">$ cat /sys/class/block/sdc/queue/hw_sector_size</span><br><span class="line">4096</span><br><span class="line"></span><br><span class="line">$ sg_format --format --size=512 /dev/sdc</span><br><span class="line">HGST      HUH728080AL4200   A7J0   peripheral_type: disk [0x0]</span><br><span class="line">&lt;&lt; supports protection information&gt;&gt;</span><br><span class="line">Mode Sense (block descriptor) data, prior to changes:</span><br><span class="line">  Number of blocks=1953506646 [0x74702556]</span><br><span class="line">  Block size=4096 [0x1000]</span><br><span class="line"></span><br><span class="line">A FORMAT will commence <span class="keyword">in</span> 10 seconds</span><br><span class="line">    ALL data on /dev/sdc will be DESTROYED</span><br><span class="line">        Press control-C to abort</span><br><span class="line">A FORMAT will commence <span class="keyword">in</span> 5 seconds</span><br><span class="line">    ALL data on /dev/sdc will be DESTROYED</span><br><span class="line">        Press control-C to abort</span><br><span class="line"></span><br><span class="line">Format has started</span><br><span class="line">FORMAT Complete</span><br><span class="line"></span><br><span class="line">$ sg_turs -v /dev/sdb</span><br><span class="line">   <span class="built_in">test</span> unit ready cdb: 00 00 00 00 00 00</span><br><span class="line">   <span class="built_in">test</span> unit ready:  Descriptor format, current;  Sense key: Not Ready Additional sense: Logical unit not ready, format <span class="keyword">in</span> progress</span><br><span class="line">   Descriptor <span class="built_in">type</span>: Information    00 00 00 00 00 00 00 00 00 00</span><br><span class="line">   Descriptor <span class="built_in">type</span>: Command specific    0x0000000000000000</span><br><span class="line">   device not ready</span><br><span class="line"></span><br><span class="line">$ sg_inq -v /dev/sdb</span><br><span class="line"><span class="comment"># it will show the process of percent</span></span><br><span class="line"></span><br><span class="line">$ cat /sys/class/block/sdc/queue/hw_sector_size</span><br><span class="line">512</span><br></pre></td></tr></table></figure>

<h4 id="intel-nvme-switch-to-AF"><a href="#intel-nvme-switch-to-AF" class="headerlink" title="intel nvme switch to AF"></a>intel nvme switch to AF</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#change 512 Bytes to 4096 Bytes</span></span><br><span class="line">$ isdct start -intelssd 0 Function=NVMEFormat LBAForma=3 SecureEraseSetting=0 ProtectionInformation=0 MetaDataSetting=0</span><br></pre></td></tr></table></figure>

<h4 id="SATA-only-support-512-and-4096-Bytes"><a href="#SATA-only-support-512-and-4096-Bytes" class="headerlink" title="SATA only support 512 and 4096 Bytes"></a>SATA only support 512 and 4096 Bytes</h4><h4 id="long-data-sector"><a href="#long-data-sector" class="headerlink" title="long-data-sector"></a>long-data-sector</h4><p>From vendor spec, only SAS device support this feature<br>You could format the driver logic sector to 4096,4112,4116,4224KB or 512,520 Bytes<br>SATA device only support 4096 or 512</p>
<p>You could get the logic sector size(4096,4112,4224), the size could be read from driver</p>
<h5 id="T10-DIF-PI"><a href="#T10-DIF-PI" class="headerlink" title="T10 DIF/PI"></a><a href="https://www.seagate.com/files/staticfiles/docs/pdf/whitepaper/safeguarding-data-from-corruption-technology-paper-tp621us.pdf" target="_blank" rel="noopener">T10 DIF/PI</a></h5><p>T10 DIF/PI for avoid data corruption from some device no CRC/ECC product, so it check the data consistency from the source to the destination</p>
<p>The user data in ecc memory(512B) —–&gt; SAS HBA/iscsi driver(520B) -&gt; SAS IO expander/or some very complicated network contains HBA or the others -&gt; Storage medium(520)<br>Because the hardware just check from input or output port from itself</p>
<p>The risk of corrupted data falling through the inherent cracks in this protection methodology is significant, and the havoc such undetected, silent data corruption could wreak (lost or inaccurate data, significant downtime) is substantial</p>
<h5 id="About-DIF-520-Bytes"><a href="#About-DIF-520-Bytes" class="headerlink" title="About DIF 520 Bytes"></a><a href="https://lwn.net/Articles/280023/" target="_blank" rel="noopener">About DIF 520 Bytes</a></h5><p>SCSI drives can usually be reformatted to 520-byte sectors, yielding 8 extra bytes per sector.  These 8 bytes have traditionally been used by RAID controllers to store internal protection information.</p>
<p>DIF (Data Integrity Field) is an extension to the SCSI Block Commands that standardizes the format of the 8 extra bytes and defines ways to interact with the contents at the protocol level.  We refer to the extra information as “integrity metadata” or “IMD”.<br>Each 8-byte DIF tuple is split into three chunks:<br>        * a 16-bit guard tag containing a CRC of the 512-byte data portion of the sector.<br>        * a 16-bit application tag which is up for grabs.<br>        * a 32-bit reference tag which contains an incrementing counter for each sector.  For DIF Type 1 it also needs to match the physical LBA on the drive.<br>There are three types of DIF defined: Type 1, Type 2, and Type 3.  My patches are Type 1 only, although Type 3 devices should work.  Type 2 depends on 32-byte CDBs and is in progress.<br>Since the DIF tuple format is standardized, both initiators and targets (as well as potentially transport switches in-between) to verify the integrity of the data going over the bus.<br>When writing, the HBA will DMA 512-byte sectors from host memory, generate the matching integrity metadata and send out 520-byte sectors on the wire.  The disk will verify the integrity of the data before committing it to stable storage<br>When reading, the drive will send 520-byte sectors to the HBA.  The HBA will verify the data integrity and DMA 512-byte sectors to host memory.<br>IOW, DIF provides means for added integrity protection between HBA and disk</p>
<ul>
<li><a href="https://www.seagate.com/files/staticfiles/docs/pdf/whitepaper/safeguarding-data-from-corruption-technology-paper-tp621us.pdf" target="_blank" rel="noopener">type 0</a><ul>
<li>Describes a drive that is not formatted with PI information bytes. This allows for legacy support in non-PI systems.</li>
</ul>
</li>
<li>type 1<ul>
<li>Provides support of PI protection using 10- and 16-byte commands. The RDPROTECT and WRTPROTECT bits allow for checking control through the CDB. Eight bytes of Protection Information are transmitted at sector boundaries across the interface if RDPROTECT and WRTPROTECT bits are non-zero values. Type I does not allow the use of 32-byte commands.</li>
</ul>
</li>
<li>type 2<ul>
<li>Provides checking control and additional expected fields within the 32-byte CDBs. Eight bytes of Protection Information are transmitted at sector boundaries across the interface if RDPROTECT and WRTPROTECT bits are non-zero values. Type II does allow the use of 10- and 16-byte commands with zero values in the RDPROTECT and WRTPROTECT fields. The drive will generate a dummy (for example, 0xFFFF) eight bytes of Protection Information in the media, but these eight bytes will not be transferred to the host during read.</li>
</ul>
</li>
<li>type 3<ul>
<li>seagate not support type 3</li>
</ul>
</li>
</ul>
<p>The T10-PI standard is an extension of the existing T10 SCSI Block Commands specification; covering communication between SCSI controllers and storage devices, Protection Information (PI) adds an extra eight bytes of information to the 512-byte sectors typical of enterprise hard drives. Increasing sector size to 520 bytes, these eight bytes of metadata consist of guard (GRD), application (APP) and reference (REF) tags that are used to verify the 512 bytes of data in the sector </p>
<p>A device that supports protection information (i.e. supports one or more protection types of 1 or higher) sets the “PROTECT” bit in its standard INQUIRY response. It  also  sets the  SPT  field  in the EXTENDED INQUIRY VPD page response to indicate which protection types it supports. The current protection type of a disk can be found in the “P_TYPE” and “PROT_EN” fields in the response of a READ CAPACITY (16) command (e.g. with the ‘sg_readcap –long’ utility).</p>
<p>Protection Information is intended as a standardized approach to system level LRC traditionally provided by systems using 520 byte formatted LBAs. Drives formatted with PI information provide the same, common LBA count (i.e. same capacity point) as non-PI formatted drives. Sequential performance of a PI drive will be reduced by approximately 1.56% due to the extra overhead of PI being transferred from the media that is not calculated as part of the data transferred to the host. To determine the full transfer rate of a PI drive, transfers should be calculated by adding the 8 extra bytes of PI to the transferred LBA length, i.e. 512 + 8 = 520. PI formatted drives are physically formatted to 520 byte sectors that store 512 bytes<br>of customer data with 8 bytes of Protection Information appended to it. The advantage of PI is that the Protection Information bits can be managed at the HBA and HBA driver level. Allowing a system that typically does not support 520 LBA formats to integrate this level of protection. Protection Information is valid with any supported LBA size. 512 LBA size is used here as common example.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">520-Bytes Sector on Protection Information Disk Drive</span><br><span class="line">512-Bytes  +  8 Bytes (metadata)</span><br><span class="line">512-Bytes &#x3D; User data</span><br><span class="line">8 Bytes &#x3D; End-to-End Check &#x3D; 2 Bytes(logical block guard, CRC) + 2 Bytes(logical block application guard) + 4 Bytes(logical block reference tag)</span><br><span class="line"></span><br><span class="line">#smart  info </span><br><span class="line">Vendor:               HGST</span><br><span class="line">Product:              HUH721212AL5200</span><br><span class="line">Revision:             NS05</span><br><span class="line">Compliance:           SPC-4</span><br><span class="line">User Capacity:        11,756,399,230,976 bytes [11.7 TB]</span><br><span class="line">Logical block size:   512 bytes</span><br><span class="line">Physical block size:  4096 bytes</span><br><span class="line">Formatted with type 2 protection</span><br><span class="line">8 bytes of protection information per logical block</span><br><span class="line">LU is fully provisioned</span><br><span class="line">Rotation Rate:        7200 rpm</span><br><span class="line"></span><br><span class="line">#type 2 ,512 example</span><br><span class="line">$ sg_readcap -l &#x2F;dev&#x2F;sdj</span><br><span class="line">Read Capacity results:</span><br><span class="line">   Protection: prot_en&#x3D;1, p_type&#x3D;1, p_i_exponent&#x3D;0 [type 2 protection]</span><br><span class="line">   Logical block provisioning: lbpme&#x3D;0, lbprz&#x3D;0</span><br><span class="line">   Last logical block address&#x3D;19134414847 (0x4747fffff), Number of logical blocks&#x3D;19134414848</span><br><span class="line">   Logical block length&#x3D;512 bytes</span><br><span class="line">   Logical blocks per physical block exponent&#x3D;3</span><br><span class="line">   Lowest aligned logical block address&#x3D;0</span><br><span class="line">Hence:</span><br><span class="line">   Device size: 9796820402176 bytes, 9342976.0 MiB, 9796.82 GB</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#type 0, 4K example</span><br><span class="line">Read Capacity results:</span><br><span class="line">   Protection: prot_en&#x3D;0, p_type&#x3D;0, p_i_exponent&#x3D;0</span><br><span class="line">   Logical block provisioning: lbpme&#x3D;0, lbprz&#x3D;0</span><br><span class="line">   Last LBA&#x3D;2441609215 (0x9187ffff), Number of logical blocks&#x3D;2441609216</span><br><span class="line">   Logical block length&#x3D;4096 bytes</span><br><span class="line">   Logical blocks per physical block exponent&#x3D;0</span><br><span class="line">   Lowest aligned LBA&#x3D;0</span><br><span class="line">Hence:</span><br><span class="line">   Device size: 10000831348736 bytes, 9537536.0 MiB, 10000.83 GB, 10.00 TB</span><br><span class="line"></span><br><span class="line">$ sg_readcap --16 -b &#x2F;dev&#x2F;sdj</span><br><span class="line">0x474800000 0x200</span><br><span class="line"></span><br><span class="line">10TB models with PI bytes</span><br><span class="line">Sector   Dec           hex          10TB models w&#x2F;o PI bytes</span><br><span class="line">512 19,134,414,848 474800000        19,532,873,728 48C400000 (10000831348736 &#x3D; 19,532,873,728 * 512 &#x3D; SATA 10TB raw size)</span><br><span class="line">520 18,845,007,872 463400000        19,134,414,848 474800000</span><br><span class="line">524 18,704,498,688 45AE00000        18,989,711,360 46BE00000</span><br><span class="line">528 18,563,989,504 452800000        18,845,007,872 463400000</span><br><span class="line">4096 2,424,569,856 90840000         2,441,609,216 91880000 (10000831348736 &#x3D; 2,441,609,216 * 4096 &#x3D; SATA 10TB raw size)</span><br><span class="line">4160 2,387,345,408 8E4C0000         2,391,801,856 8E900000</span><br><span class="line">4192 2,368,995,328 8D340000         2,373,713,920 8D7C0000 1</span><br><span class="line">4224 2,351,169,536 8C240000         2,355,625,984 8C680000</span><br><span class="line"></span><br><span class="line"># models with PI bytes, the page only show 512 or 4096 bytes, the extra space overhead hide in HDD</span><br><span class="line"># modlls w&#x2F;o PI bytes, smartctl could get 520,524,4160,4192,4224 from logic sector bytes</span><br></pre></td></tr></table></figure>

<h5 id="T10-DIX-and-PI"><a href="#T10-DIX-and-PI" class="headerlink" title="T10 DIX and PI"></a><a href="https://sp.ts.fujitsu.com/dmsp/Publications/public/dx_s3_Oracle_Linux_T10_PI_E16G_en.pdf" target="_blank" rel="noopener">T10 DIX and PI</a></h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">|--------------Server----------------|                  |-------Storage system----|</span><br><span class="line">Application -&gt; OS -&gt; IO controller/HBA -&gt; SAN/Switch -&gt; Controller/switch -&gt; Driver</span><br><span class="line">|--------------DIX------------||----------------------PI--------------------------|</span><br></pre></td></tr></table></figure>
<p>DIX end at HBA input ( add extra 8 Bytes for protect in every level )<br>PI start at HBA output ( add extra 8 Bytes for protect in every level )<br>DIX + PI means end to end data protection<br>In some case, maybe you just support T10 PI and not DIX support</p>
<h3 id="Security-erasing"><a href="#Security-erasing" class="headerlink" title="Security erasing"></a>Security erasing</h3><p>SAS</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sg_format --format /dev/sdx</span><br></pre></td></tr></table></figure>

<p>SATA</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hdparm --user-master u --security-set-pass password /dev/sdx</span><br></pre></td></tr></table></figure>

<p>NVME</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ nvme list</span><br><span class="line">Node             SN                   Model                                    Namespace Usage                      Format           FW Rev</span><br><span class="line">---------------- -------------------- ---------------------------------------- --------- -------------------------- ---------------- --------</span><br><span class="line">/dev/nvme0n1     xxxxxxxxxxxxxxx      INTEL SSDPED1K375GA                      1         375.08  GB / 375.08  GB    512   B +  0 B   E2010324</span><br><span class="line"></span><br><span class="line">$ nvme id-ctrl -H  /dev/nvme0n1 | grep format -i</span><br><span class="line">  [1:1] : 0x1   Format NVM Supported</span><br><span class="line">  [0:0] : 0     Admin Vendor Specific Commands uses Vendor Specific Format</span><br><span class="line">  [0:0] : 0     Format Applies to Single Namespace(s)</span><br><span class="line">  [0:0] : 0     NVM Vendor Specific Commands uses Vendor Specific Format</span><br><span class="line"></span><br><span class="line">$ nvme format /dev/nvme0n1 --ses=1</span><br><span class="line"></span><br><span class="line">$ nvme id-ns /dev/nvme1n1 | grep LBA</span><br><span class="line">LBA Format  0 : Metadata Size: 0   bytes - Data Size: 512 bytes - Relative Performance: 0x1 Better</span><br><span class="line">LBA Format  1 : Metadata Size: 8   bytes - Data Size: 512 bytes - Relative Performance: 0x3 Degraded</span><br><span class="line">LBA Format  2 : Metadata Size: 0   bytes - Data Size: 4096 bytes - Relative Performance: 0 Best  (<span class="keyword">in</span> use)</span><br><span class="line">LBA Format  3 : Metadata Size: 8   bytes - Data Size: 4096 bytes - Relative Performance: 0x2 Good</span><br><span class="line"></span><br><span class="line">$ nvme format /dev/nvme1n1 -l 2</span><br></pre></td></tr></table></figure>

<h3 id="Enable-the-blk-mq-and-scsi-mq"><a href="#Enable-the-blk-mq-and-scsi-mq" class="headerlink" title="Enable the blk_mq and scsi_mq"></a>Enable the blk_mq and scsi_mq</h3><p>scsi-mq:specify scsi_mod.use_blk_mq=y<br>blk-mq infrastructure if the dm_mod.use_blk_mq=y</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ grubby --update-kernel=ALL --args=<span class="string">'scsi_mod.use_blk_mq=y dm_mod.use_blk_mq=y'</span></span><br><span class="line">$ reboot</span><br><span class="line">$ cat  /sys/block/dm-X/dm/use_blk_mq</span><br><span class="line">$ tree /sys/class/block/sdl/mq /sys/class/block/dm-0/mq</span><br></pre></td></tr></table></figure>

<h3 id="lsscsi"><a href="#lsscsi" class="headerlink" title="lsscsi"></a>lsscsi</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">$ lsscsi -t | grep sdio</span><br><span class="line">[4:1:8:0]   disk    sas:0x5000c657afc33e1d          /dev/sdio</span><br><span class="line"></span><br><span class="line">$ lsscsi -t -L 4:1:8:0</span><br><span class="line">[4:1:8:0]   disk    sas:0x5000c657afc33e1d          /dev/sdio</span><br><span class="line">  transport=sas</span><br><span class="line">  vendor=HGST</span><br><span class="line">  model=HUH721010AL5200</span><br><span class="line">  bay_identifier=7</span><br><span class="line">  enclosure_device:Slot07</span><br><span class="line">  enclosure_identifier=0x50030103403449ca</span><br><span class="line">  initiator_port_protocols=none</span><br><span class="line">  initiator_response_timeout=1744</span><br><span class="line">  I_T_nexus_loss_timeout=1744</span><br><span class="line">  phy_identifier=33</span><br><span class="line">  ready_led_meaning=0</span><br><span class="line">  sas_address=0x5000c657afc33e1d</span><br><span class="line">  target_port_protocols=ssp</span><br><span class="line">  tlr_enabled=0</span><br><span class="line">  tlr_supported=0</span><br><span class="line"></span><br><span class="line">$ lsscsi -gis | grep sdio</span><br><span class="line">[4:1:8:0]   disk    HGST     HUH721010AL5200  A21D  /dev/sdio  35000c657afc33e1c  /dev/sg180  10.0TB</span><br><span class="line"></span><br><span class="line">$ lsblk -o NAME,MODEL,SERIAL,SIZE,STATE,TYPE,WWN --nodeps | grep sdio</span><br><span class="line">sdio HUH721010AL5200  5000c657afc33e1c                   9.1T running disk 0x5000c657afc33e1c</span><br><span class="line"></span><br><span class="line">$ $ lsscsi -t -H</span><br><span class="line">[0]    megaraid_sas</span><br><span class="line">[10]    ahci          sata:</span><br><span class="line">[11]    ahci          sata:</span><br><span class="line">[12]    mpt3sas       sas:0x500605b00bfa0982</span><br><span class="line">[13]    mpt3sas       sas:0x500605b00acf0542</span><br><span class="line">[14]    mpt3sas       sas:0x500605b00bfac033</span><br><span class="line"></span><br><span class="line">$ lsscsi -tiv</span><br><span class="line">[0:0:7:0]    disk    sas:0x500056b3787358c7          /dev/sdh   -</span><br><span class="line">  dir: /sys/bus/scsi/devices/0:0:7:0  [/sys/devices/pci0000:ae/0000:ae:00.0/0000:af:00.0/host0/port-0:0/expander-0:0/port-0:0:7/end_device-0:0:7/target0:0:7/0:0:7:0]</span><br><span class="line">[0:0:8:0]    disk    sas:0x500056b3787358c8          /dev/sdi   -</span><br><span class="line">  dir: /sys/bus/scsi/devices/0:0:8:0  [/sys/devices/pci0000:ae/0000:ae:00.0/0000:af:00.0/host0/port-0:0/expander-0:0/port-0:0:8/end_device-0:0:8/target0:0:8/0:0:8:0]</span><br><span class="line">[0:0:9:0]    disk    sas:0x5000cca26c1b8631          /dev/sdj   35000cca26c1b8630</span><br><span class="line"></span><br><span class="line"><span class="comment"># get single port</span></span><br><span class="line">[1:0:0:0]    disk    sas:0x5000cca26fae54a6          /dev/sda   35000cca26fae54a4  11.7TB</span><br><span class="line">  dir: /sys/bus/scsi/devices/1:0:0:0  [/sys/devices/pci0000:00/0000:00:01.0/0000:01:00.0/host1/port-1:0/expander-1:0/port-1:0:0/expander-1:1/port-1:1:0/end_device-1:1:0/target1:0:0/1:0:0:0]</span><br><span class="line">[1:0:1:0]    enclosu sas:0x500c0ff00b40aa3e          -          -       -</span><br><span class="line">  dir: /sys/bus/scsi/devices/1:0:1:0  [/sys/devices/pci0000:00/0000:00:01.0/0000:01:00.0/host1/port-1:0/expander-1:0/port-1:0:4/end_device-1:0:4/target1:0:1/1:0:1:0]</span><br><span class="line">[1:0:2:0]    disk    sas:0x5000cca26fabd8c2          /dev/sdb   35000cca26fabd8c0  11.7TB</span><br><span class="line">  dir: /sys/bus/scsi/devices/1:0:2:0  [/sys/devices/pci0000:00/0000:00:01.0/0000:01:00.0/host1/port-1:0/expander-1:0/port-1:0:0/expander-1:1/port-1:1:1/end_device-1:1:1/target1:0:2/1:0:2:0]</span><br><span class="line">.......</span><br><span class="line"></span><br><span class="line">[1:0:87:0]   disk    sas:0x5000cca26fbac14e          /dev/sdcf  35000cca26fbac14c  11.7TB</span><br><span class="line">  dir: /sys/bus/scsi/devices/1:0:87:0  [/sys/devices/pci0000:00/0000:00:01.0/0000:01:00.0/host1/port-1:0/expander-1:0/port-1:0:3/expander-1:4/port-1:4:27/end_device-1:4:27/target1:0:87/1:0:87:0]</span><br><span class="line">[1:0:88:0]   process sas:0x500c0ff5f12425fe          -          -       -</span><br><span class="line">  dir: /sys/bus/scsi/devices/1:0:88:0  [/sys/devices/pci0000:00/0000:00:01.0/0000:01:00.0/host1/port-1:0/expander-1:0/port-1:0:3/expander-1:4/port-1:4:28/end_device-1:4:28/target1:0:88/1:0:88:0]</span><br><span class="line"></span><br><span class="line">$ grep 11.7 /tmp/tmp</span><br><span class="line">[1:0:0:0]    disk    sas:0x5000cca26fae54a6          /dev/sda   35000cca26fae54a4  11.7TB</span><br><span class="line">[1:0:2:0]    disk    sas:0x5000cca26fabd8c2          /dev/sdb   35000cca26fabd8c0  11.7TB</span><br><span class="line">[1:0:3:0]    disk    sas:0x5000cca26fb405d2          /dev/sdc   35000cca26fb405d0  11.7TB</span><br><span class="line">[1:0:4:0]    disk    sas:0x5000cca26fb99436          /dev/sdd   35000cca26fb99434  11.7TB</span><br><span class="line">[1:0:5:0]    disk    sas:0x5000cca26fbac11a          /dev/sde   35000cca26fbac118  11.7TB</span><br><span class="line">[1:0:6:0]    disk    sas:0x5000cca26fbac962          /dev/sdf   35000cca26fbac960  11.7TB</span><br><span class="line">[1:0:7:0]    disk    sas:0x5000cca26fb5c9b2          /dev/sdg   35000cca26fb5c9b0  11.7TB</span><br><span class="line">[1:0:8:0]    disk    sas:0x5000cca26fad67be          /dev/sdh   35000cca26fad67bc  11.7TB</span><br><span class="line">[1:0:9:0]    disk    sas:0x5000cca26fb7d912          /dev/sdi   35000cca26fb7d910  11.7TB</span><br><span class="line">[1:0:10:0]   disk    sas:0x5000cca26fbacac2          /dev/sdj   35000cca26fbacac0  11.7TB</span><br><span class="line">[1:0:11:0]   disk    sas:0x5000cca26fbac81a          /dev/sdk   35000cca26fbac818  11.7TB</span><br><span class="line">.......</span><br><span class="line">[1:0:78:0]   disk    sas:0x5000cca26fa140aa          /dev/sdbw  35000cca26fa140a8  11.7TB</span><br><span class="line">[1:0:79:0]   disk    sas:0x5000cca26fbac816          /dev/sdbx  35000cca26fbac814  11.7TB</span><br><span class="line">[1:0:80:0]   disk    sas:0x5000cca26fb99fba          /dev/sdby  35000cca26fb99fb8  11.7TB</span><br><span class="line">[1:0:81:0]   disk    sas:0x5000cca26faa42da          /dev/sdbz  35000cca26faa42d8  11.7TB</span><br><span class="line">[1:0:82:0]   disk    sas:0x5000cca26fad6776          /dev/sdca  35000cca26fad6774  11.7TB</span><br><span class="line">[1:0:83:0]   disk    sas:0x5000cca26fa46c8e          /dev/sdcb  35000cca26fa46c8c  11.7TB</span><br><span class="line">[1:0:84:0]   disk    sas:0x5000cca26fbab7a6          /dev/sdcc  35000cca26fbab7a4  11.7TB</span><br><span class="line">[1:0:85:0]   disk    sas:0x5000cca26fbab7e2          /dev/sdcd  35000cca26fbab7e0  11.7TB</span><br><span class="line">[1:0:86:0]   disk    sas:0x5000cca26fb5ca42          /dev/sdce  35000cca26fb5ca40  11.7TB</span><br><span class="line">[1:0:87:0]   disk    sas:0x5000cca26fbac14e          /dev/sdcf  35000cca26fbac14c  11.7TB</span><br></pre></td></tr></table></figure>

<h3 id="udevinfo"><a href="#udevinfo" class="headerlink" title="udevinfo"></a><a href="https://sites.google.com/site/itmyshare/system-admin-tips-and-tools/udevadm---useage-examples" target="_blank" rel="noopener">udevinfo</a></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">$ udevadm info --query=property --name /dev/sdd</span><br><span class="line">$ udevadm info --query=path --name /dev/sdd</span><br><span class="line">$ udevadm info --query=symlink --name /dev/sdd</span><br><span class="line">$ udevadm info --a --name=/dev/sdd</span><br><span class="line">$ udevadm info --attribute-walk --name /dev/sdd</span><br><span class="line"></span><br><span class="line">$ udevadm info -a -p $(udevadm info -q path -n /dev/sda)</span><br><span class="line">$ udevadm info -a -p /sys/class/net/eth0</span><br><span class="line">$ udevadm info -q path -n /dev/sda1</span><br><span class="line"></span><br><span class="line"><span class="comment"># trigger, remember to have --dry-run option if you run it on production node.</span></span><br><span class="line">$ udevadm trigger --verbose --dry-run --<span class="built_in">type</span>=devices --subsystem-match=scsi_host</span><br><span class="line">$ udevadm trigger --verbose --dry-run --<span class="built_in">type</span>=devices --subsystem-match=scsi_disk</span><br><span class="line">$ udevadm trigger --verbose --dry-run --<span class="built_in">type</span>=devices --subsystem-match=scsi_tape</span><br><span class="line">$ udevadm trigger --verbose --dry-run --<span class="built_in">type</span>=devices --subsystem-match=fc_host </span><br><span class="line"></span><br><span class="line"><span class="comment"># This option only waits for events triggered by the same command to finish</span></span><br><span class="line">$ udevadm settle</span><br><span class="line"></span><br><span class="line"><span class="comment"># control </span></span><br><span class="line">$ udevadm control --reload-rules</span><br><span class="line">$ --<span class="built_in">log</span>-priority=&lt;level&gt;   <span class="built_in">set</span> the udev <span class="built_in">log</span> level <span class="keyword">for</span> the daemon</span><br><span class="line"></span><br><span class="line"><span class="comment"># monitor</span></span><br><span class="line">$ udevadm monitor --<span class="built_in">help</span></span><br><span class="line">Usage: udevadm monitor [--property] [--kernel] [--udev] [--<span class="built_in">help</span>]</span><br><span class="line">  --property                    <span class="built_in">print</span> the event properties</span><br><span class="line">  --kernel                      <span class="built_in">print</span> kernel uevents</span><br><span class="line">  --udev                        <span class="built_in">print</span> udev events</span><br><span class="line">  --subsystem-match=&lt;subsystem&gt; filter events</span><br><span class="line">  --<span class="built_in">help</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># test</span></span><br><span class="line">$ udevadm <span class="built_in">test</span> /block/sdd</span><br></pre></td></tr></table></figure>

<h3 id="Flush-cache-data"><a href="#Flush-cache-data" class="headerlink" title="Flush cache data"></a>Flush cache data</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## flush fs buff</span></span><br><span class="line">$ sync</span><br><span class="line"></span><br><span class="line"><span class="comment"># Flush fs buff</span></span><br><span class="line">$ blockdev --flushbufs /dev/sdxx</span><br><span class="line"></span><br><span class="line"><span class="comment">#or for zfs</span></span><br><span class="line">$ zpool <span class="built_in">export</span> your_pool</span><br><span class="line"></span><br><span class="line"><span class="comment"># Flush the SAS dev buff</span></span><br><span class="line">$ sdparm --<span class="built_in">command</span>=sync /dev/sdxx</span><br><span class="line"><span class="comment">#spindown the device</span></span><br><span class="line">$ sdparm --<span class="built_in">command</span>=stop /dev/sdxx</span><br><span class="line"></span><br><span class="line"><span class="comment"># Flush the SATA dev buff</span></span><br><span class="line">$ hdparm -F /dev/sdxx</span><br><span class="line"></span><br><span class="line">$ storcli64 /c0 <span class="built_in">set</span> flushwriteverify=on</span><br><span class="line">$ storcli64 /c0 show flushwriteverify</span><br><span class="line">$ storcli64 /c0 flushcache</span><br><span class="line">Description = Adapter and/or disk caches flushed successfully.</span><br></pre></td></tr></table></figure>

<h3 id="dev-info"><a href="#dev-info" class="headerlink" title="dev info"></a><a href="https://www.ibm.com/support/knowledgecenter/en/linuxonibm/com.ibm.linux.z.lgdd/lgdd_t_fcp_wrk_actinfo.html" target="_blank" rel="noopener">dev info</a></h3><p>/sys/class/scsi_device/<device_name>/device/<attribute></p>
<p>ioerr_cnt       The number of SCSI commands that completed with an error.<br>scsi_level      The SCSI revision level, received from inquiry data.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">access_denied   Flag that indicates whether access to the device is restricted by the FCP channel.The value is 1 if access is denied and 0 if access is permitted.If access is denied to your Linux instance, confirm that your SCSI devices are configured as intended. Also, be sure that you really want to share a SCSI device. For shared access to a SCSI device, preferably use NPIV). You might also use different FCP channels or target ports.</span><br><span class="line">access_shared   This attribute is obsolete. The value is always 0.</span><br><span class="line">access_readonly This attribute is obsolete. The value is always 0.</span><br><span class="line">ked     Flag that indicates whether the device is in blocked state (0 or 1).</span><br><span class="line">iocounterbits   The number of bits used for I&#x2F;O counters.</span><br><span class="line">iodone_cnt      The number of completed or rejected SCSI commands.</span><br><span class="line">ioerr_cnt       The number of SCSI commands that completed with an error.</span><br><span class="line">iorequest_cnt   The number of issued SCSI commands.</span><br><span class="line">queue_type      The type of queue for the SCSI device. The value can be one of the following:</span><br><span class="line">                none</span><br><span class="line">                simple</span><br><span class="line">                ordered</span><br><span class="line">model   The model of the SCSI device, received from inquiry data.</span><br><span class="line">rev     The revision of the SCSI device, received from inquiry data.</span><br><span class="line">scsi_level      The SCSI revision level, received from inquiry data.</span><br><span class="line">type    The type of the SCSI device, received from inquiry data.</span><br><span class="line">vendor  The vendor of the SCSI device, received from inquiry data.</span><br><span class="line">fcp_lun The LUN of the SCSI device in 64-bit format.</span><br><span class="line">hba_id  The bus ID of the SCSI device.</span><br><span class="line">wwpn    The WWPN of the remote port.</span><br><span class="line">zfcp_access_denied      Flag that indicates whether access to the device is restricted by the FCP channel.The value is 1 if access is denied and 0 if access is permitted. If access is denied to your Linux instance, confirm that your SCSI devices are configured as intended. Also, be sure that you really want to share a SCSI device. For shared access to a SCSI device, preferably use NPIV). You might also use different FCP channels or target ports.</span><br><span class="line">zfcp_in_recovery        Shows if unit is in recovery (0 or 1).Shows if unit is in recovery (2 or 1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### Encrypt block device</span><br><span class="line">#### *Input password*     </span><br><span class="line">or you can not use openssl          </span><br><span class="line">&#96;&#96;&#96; bash</span><br><span class="line">cryptsetup luksFormat --cipher aes-xts-plain64 --key-size 512 --hash sha256 &#x2F;dev&#x2F;vdb     </span><br><span class="line">WARNING!     </span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;     </span><br><span class="line">This will overwrite data on &#x2F;dev&#x2F;vdb irrevocably.     </span><br><span class="line">     </span><br><span class="line">Are you sure? (Type uppercase yes): YES      </span><br><span class="line">Enter passphrase:      </span><br><span class="line">Verify passphrase:</span><br></pre></td></tr></table></figure>

<h4 id="mapper-test-device"><a href="#mapper-test-device" class="headerlink" title="mapper test device"></a><em>mapper test device</em></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">cryptsetup luksOpen /dev/vdb <span class="built_in">test</span>     </span><br><span class="line">Enter passphrase <span class="keyword">for</span> /dev/vdb:     </span><br><span class="line">``` </span><br><span class="line">or     </span><br><span class="line">``` bash</span><br><span class="line"><span class="built_in">cd</span> /dev/shm     </span><br><span class="line">openssl rand 128 -hex -out ./key     </span><br><span class="line">openssl aes-256-cbc -<span class="keyword">in</span> ./key -out key.enc     </span><br><span class="line"></span><br><span class="line">Verifying - enter aes-256-cbc encryption password:</span><br><span class="line">openssl aes-256-cbc -d -<span class="keyword">in</span> ./key.enc | cryptsetup [--allow-discards] --key-file=- luksOpen /dev/vdb <span class="built_in">test</span>     </span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line">If you have a SSD, you may want to use --allow-discards. It creates an information leak but it enhances your SSD’s lifetime.     </span><br><span class="line"></span><br><span class="line">``` bash</span><br><span class="line">mkfs.ext4 /dev/mapper/<span class="built_in">test</span>     </span><br><span class="line">cryptsetup luksDump /dev/vdb     </span><br><span class="line">     </span><br><span class="line">``` bash     </span><br><span class="line">LUKS header information <span class="keyword">for</span> /dev/vdb     </span><br><span class="line">Key Slot 0: ENABLED     </span><br><span class="line">	Iterations:         	80604     </span><br><span class="line">	Salt:               	c4 c0 08 9c 77 ef 57 a5 d2 62 f4 94 03 56 24 7a      </span><br><span class="line">	                      	86 0c f4 c6 06 6f 9e 01 80 <span class="built_in">fc</span> 0f 1d 3b a9 59 87      </span><br><span class="line">	Key material offset:	8     </span><br><span class="line">	AF stripes:            	4000     </span><br><span class="line">Key Slot 1: DISABLED</span><br></pre></td></tr></table></figure>

<h4 id="Add-remove-key"><a href="#Add-remove-key" class="headerlink" title="Add/remove key"></a><em>Add/remove key</em></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cryptsetup luksAddKey --key-slot 1 /dev/vdb     </span><br><span class="line">cryptsetup luksRemoveKey /dev/vdb</span><br></pre></td></tr></table></figure>

<h4 id="Back-restore-header"><a href="#Back-restore-header" class="headerlink" title="Back/restore header"></a><em>Back/restore header</em></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cryptsetup luksHeaderBackup /dev/vdb --header-backup-file /root/vdb-header-backup     </span><br><span class="line">cryptsetup luksHeaderRestore /dev/vdb --header-backup-file /root/vdb-header-backup</span><br></pre></td></tr></table></figure>

<h4 id="is-luks-partition"><a href="#is-luks-partition" class="headerlink" title="is luks partition"></a><em>is luks partition</em></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cryptsetup -v isLuks /dev/vdb</span><br></pre></td></tr></table></figure>

<h4 id="Clean-luks-partition"><a href="#Clean-luks-partition" class="headerlink" title="Clean luks partition"></a><em>Clean luks partition</em></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">head -c 3145728 /dev/zero &gt; /dev/vdb;sync</span><br></pre></td></tr></table></figure>
<p>The default LUKS header (with only one key-slot enabled) takes 1052672 bytes, what is slightly more than 1 MiB. Having 2 key-slots enabled this would extend the header almost twice (key-slots * stripes * keysize + offset bytes). Therefore overwriting the first 3 MiB would do the job for us </p>
<h3 id="Why-Trim"><a href="#Why-Trim" class="headerlink" title="Why Trim"></a><a href="https://en.wikipedia.org/wiki/Trim_(computing)" target="_blank" rel="noopener">Why Trim</a></h3><p>The Trim command is designed to enable the operating system to notify the SSD which pages no longer contain valid data due to erases either by the user or operating system itself. During a delete operation, the OS will mark the sectors as free for new data and send a Trim command to the SSD to mark them as not containing valid data. After that the SSD knows not to preserve the contents of the block when writing a page, resulting in less write amplification with fewer writes to the flash, higher write speed, and increased drive life.<br>Different SSDs implement the Trim command somewhat differently, so performance can vary.<br><img src="http://images.anandtech.com/reviews/storage/Intel/34nmSSD/Review/garbagecollection.png" alt=""></p>
<h4 id="Openzfs-on-linux"><a href="#Openzfs-on-linux" class="headerlink" title="Openzfs on linux"></a>Openzfs on linux</h4><p><a href="https://github.com/zfsonlinux/zfs/pull/1016" target="_blank" rel="noopener">not support trim funtion</a><br><a href="http://list.zfsonlinux.org/pipermail/zfs-discuss/2016-January/024437.html" target="_blank" rel="noopener">expect to get a upgrade this year that will add TRIM support</a></p>
<h4 id="Trim-patch-for-ZOL"><a href="#Trim-patch-for-ZOL" class="headerlink" title="Trim patch for ZOL"></a>Trim patch for ZOL</h4><p><a href="https://github.com/zfsonlinux/zfs/pull/924" target="_blank" rel="noopener">DO NOT APPLY THIS PATCH IF YOU CARE ABOUT YOUR DATA</a></p>
<h4 id="Mdadm"><a href="#Mdadm" class="headerlink" title="Mdadm"></a>Mdadm</h4><p><a href="http://kernelnewbies.org/Linux_3.7#head-2fd9b183a4623d96e69ed24f88e0eb83217fa8df" target="_blank" rel="noopener">Since version 3.7 of the Linux kernel mainline, md supports TRIM operations for the underlying solid-state drives (SSDs), for linear, RAID 0, RAID 1, RAID 5 and RAID 10 layouts</a><br><a href="https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html-single/6.5_Release_Notes/" target="_blank" rel="noopener">CentOS 6.5 The mdadm tool now supports the TRIM commands for RAID0, RAID1, and RAID10.</a></p>
<h4 id="LSI-Check-Interoperability-and-Compatibility"><a href="#LSI-Check-Interoperability-and-Compatibility" class="headerlink" title="LSI Check Interoperability and Compatibility"></a><a href="http://www.avagotech.com/support/interop-compatibility" target="_blank" rel="noopener">LSI Check Interoperability and Compatibility</a></h4><p><a href="http://docs.avagotech.com/docs-and-downloads/raid-controllers/MegaRAID_SAS_Gen3CompatibilityList.pdf" target="_blank" rel="noopener">MegaRAID SAS Gen3 Compatibility List</a><br><a href="http://docs.avagotech.com/docs-and-downloads/raid-controllers/raid-controllers-common-files/iMR_SAS_Gen3CompatibilityList.pdf" target="_blank" rel="noopener">iMR SAS Gen3 Compatibility List</a><br><a href="http://www.media-clone.net/v/vspfiles/downloads/LSI_6Gb_SAS_SATA_HBA_Compatibility_List.pdf" target="_blank" rel="noopener">LSI_6Gb_SAS_SATA_HBA Compatibility List</a><br>Just Compatibility, trim support not clean</p>
<h4 id="HP-Raid-support"><a href="#HP-Raid-support" class="headerlink" title="HP Raid support"></a>HP Raid support</h4><p><a href="http://h20195.www2.hp.com/V2/GetPDF.aspx/4AA5-8637ENW" target="_blank" rel="noopener">Is TRIM supported when using RAID with SSDs?</a><br><img src="/img/hp-trim-support.png" alt=""><br>Raid 1,10,0 could be support<br>Raid 1E,5,6 has not support</p>
<h3 id="Re-assign-bad-block"><a href="#Re-assign-bad-block" class="headerlink" title="Re-assign bad block"></a><a href="https://www.smartmontools.org/wiki/BadBlockHowto" target="_blank" rel="noopener">Re-assign bad block</a></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># dmesg error</span></span><br><span class="line"> sd 13:0:10:0: attempting task abort! scmd(ffff88bdf0eb8000)</span><br><span class="line"> sd 13:0:10:0: [sdff] tag<span class="comment">#22 CDB: Read(16) 88 00 00 00 00 04 16 2b fa 66 00 00 00 6c 00 00</span></span><br><span class="line"> scsi target13:0:10: _scsih_tm_display_info: handle(0x0015), sas_address(0x5000cca251b4462e), phy(37)</span><br><span class="line"> scsi target13:0:10: enclosurelogical id(0x500304800928dc3f), slot(10)</span><br><span class="line"> scsi target13:0:10: enclosure level(0x0000), connector name(     )</span><br><span class="line"> sd 13:0:10:0: task abort: SUCCESS scmd(ffff88bdf0eb8000)</span><br><span class="line"> sd 13:0:10:0: [sdff] tag<span class="comment">#22 FAILED Result: hostbyte=DID_TIME_OUT driverbyte=DRIVER_OK</span></span><br><span class="line"> sd 13:0:10:0: [sdff] tag<span class="comment">#22 CDB: Read(16) 88 00 00 00 00 04 16 2b fa 66 00 00 00 6c 00 00</span></span><br><span class="line"> blk_update_request: I/O error, dev sdff, sector 17551850086</span><br><span class="line"> sd 13:0:10:0: attempting task abort! scmd(ffff88b39ff33800)</span><br><span class="line"> sd 13:0:10:0: [sdff] tag<span class="comment">#21 CDB: Read(16) 88 00 00 00 00 04 16 2b f9 78 00 00 00 ee 00 00</span></span><br><span class="line"> scsi target13:0:10: _scsih_tm_display_info: handle(0x0015), sas_address(0x5000cca251b4462e), phy(37)</span><br><span class="line"> scsi target13:0:10: enclosurelogical id(0x500304800928dc3f), slot(10)</span><br><span class="line"> scsi target13:0:10: enclosure level(0x0000), connector name(     )</span><br><span class="line"> sd 13:0:10:0: task abort: SUCCESS scmd(ffff88b39ff33800)</span><br><span class="line"></span><br><span class="line">$ smartctl -t long /dev/sdff</span><br><span class="line"></span><br><span class="line"><span class="comment">### after test</span></span><br><span class="line">smartctl -l selftest /dev/sdb</span><br><span class="line">smartctl version 5.37 [i686-pc-linux-gnu] Copyright (C) 2002-6 Bruce Allen</span><br><span class="line">Home page is http://smartmontools.sourceforge.net/</span><br><span class="line">SMART Self-test <span class="built_in">log</span></span><br><span class="line">Num  Test              Status            segment  LifeTime  LBA_first_err [SK ASC ASQ]</span><br><span class="line">     Description                         number   (hours)</span><br><span class="line"><span class="comment"># 1  Background long   Failed in segment      -     354           1193046 [0x3 0x11 0x0]</span></span><br><span class="line"><span class="comment"># 2  Background short  Completed              -     323                 - [-   -    -]</span></span><br><span class="line"><span class="comment"># 3  Background short  Completed              -     194                 - [-   -    -]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#That means sometimes the connection quality was bad</span></span><br><span class="line">$ sg_verify --lba=1193046 /dev/sdff</span><br><span class="line">$ <span class="built_in">echo</span> $?</span><br><span class="line">0</span><br><span class="line"></span><br><span class="line">0x123456=1193046</span><br><span class="line"></span><br><span class="line"><span class="comment">#The link case</span></span><br><span class="line">$ sg_verify --lba=1193046 /dev/sdb</span><br><span class="line">verify (10):  Fixed format, current;  Sense key: Medium Error</span><br><span class="line"> Additional sense: Unrecovered <span class="built_in">read</span> error</span><br><span class="line">  Info fld=0x123456 [1193046]</span><br><span class="line">  Field replaceable unit code: 228</span><br><span class="line">  Actual retry count: 0x008b</span><br><span class="line">medium or hardware error, reported lba=0x123456</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now the GLIST length is checked before the block reassignment:</span></span><br><span class="line"></span><br><span class="line">$ sg_reassign --grown /dev/sdb</span><br><span class="line">&gt;&gt; Elements <span class="keyword">in</span> grown defect list: 0</span><br><span class="line"><span class="comment"># And now for the actual reassignment followed by another check of the GLIST length:</span></span><br><span class="line"></span><br><span class="line">$ sg_reassign --address=1193046 /dev/sdb</span><br><span class="line"></span><br><span class="line">$ sg_reassign --grown /dev/sdb</span><br><span class="line">&gt;&gt; Elements <span class="keyword">in</span> grown defect list: 1</span><br><span class="line"><span class="comment"># The GLIST length has grown by one as expected. If the disk was unable to recover any data, then the "new" block at lba 0x123456 has vendor specific data in it. The sg_reassign utility can also do bulk reassigns, see man sg_reassign for more information.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The dd command could be used to read the contents of the "new" block:</span></span><br><span class="line"></span><br><span class="line">$ dd <span class="keyword">if</span>=/dev/sdb iflag=direct skip=1193046 of=blk.img bs=512 count=1</span><br><span class="line"><span class="comment"># and a hex editor [11] used to view and potentially change the blk.img file. An altered blk.img file (or /dev/zero) could be written back with:</span></span><br><span class="line"></span><br><span class="line">$ dd <span class="keyword">if</span>=blk.img of=/dev/sdb seek=1193046 oflag=direct bs=512 count=1</span><br><span class="line"><span class="comment"># More work may be needed at the file system level, especially if the reassigned block held critical file system information such as a superblock or a directory.</span></span><br></pre></td></tr></table></figure>

<h3 id="linux-block-integrity"><a href="#linux-block-integrity" class="headerlink" title="linux block integrity"></a>linux block integrity</h3><p>config BLK_DEV_INTEGRITY</p>
<p><a href="https://www.redhat.com/zh/blog/what-bit-rot-and-how-can-i-detect-it-rhel" target="_blank" rel="noopener">Regarding support status: dm-integrity is not labeled as TechPreview, it is supported. Heavy stacks of RAID1 on top, with mdadm or LVM-raid, are not yet widely tested or recommended for production</a></p>
<p>Issues, </p>
<ul>
<li>reformat, it ‘s a long time for 10TB+ HDD</li>
<li>performance impact</li>
</ul>
<p>dm-integrity</p>
<ul>
<li>Emulates per-sector metadata</li>
<li>Optionally standalone mode (CRC32)</li>
</ul>
<p>Because the T13/ATA External Path Protection has <a href="https://www.spinics.net/lists/raid/msg41308.html" target="_blank" rel="noopener">dead</a><br>I can ‘t see any support from raid/HBA vendor<br>I found linux community support the block integrity, linux kernel need to &gt;= 4.12</p>
<h4 id="test"><a href="#test" class="headerlink" title="test"></a>test</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">$ dd <span class="keyword">if</span>=/dev/zero of=rawfile bs=1M count=128</span><br><span class="line">$ MYLOOP=$(losetup -f --show rawfile)</span><br><span class="line">$ integritysetup format <span class="variable">$MYLOOP</span> -I crc32</span><br><span class="line">$ integritysetup open <span class="variable">$MYLOOP</span> mydata -I crc32</span><br><span class="line">$ mkfs.xfs /dev/mapper/mydata</span><br><span class="line">$ mount /dev/mapper/mydata /mnt</span><br><span class="line">$ yes &gt;/mnt/infile</span><br><span class="line">$ md5sum /mnt/infile </span><br><span class="line">13e14c50aaf2054d987663ed31b5f786  /mnt/infile</span><br><span class="line">$ umount /mnt/</span><br><span class="line">$ losetup -d <span class="variable">$MYLOOP</span></span><br><span class="line">$ integritysetup close mydata</span><br><span class="line">$ dd <span class="keyword">if</span>=rawfile bs=1 count=10 skip=$((50*1024*1024)) 2&gt;/dev/null|hexdump -vC</span><br><span class="line">00000000  79 0a 79 0a 79 0a 79 0a  79 0a |y.y.y.y.y.|</span><br><span class="line">0000000a</span><br><span class="line">$ <span class="built_in">echo</span> <span class="string">'x'</span> | dd of=rawfile bs=1 count=1 seek=$((50*1024*1024)) conv=notrunc</span><br><span class="line">$ dd <span class="keyword">if</span>=rawfile bs=1 count=10 skip=$((50*1024*1024)) 2&gt;/dev/null|hexdump -vC</span><br><span class="line">00000000  78 0a 79 0a 79 0a 79 0a  79 0a |x.y.y.y.y.|</span><br><span class="line">0000000a</span><br><span class="line"></span><br><span class="line"><span class="comment"># you can see the log in demsg</span></span><br><span class="line">[Thu Jan 23 12:56:07 2020] device-mapper: integrity: Checksum failed at sector 0x18468</span><br><span class="line"></span><br><span class="line">$ integritysetup status mydata</span><br><span class="line">/dev/mapper/mydata is active and is <span class="keyword">in</span> use.</span><br><span class="line">  <span class="built_in">type</span>:    INTEGRITY</span><br><span class="line">  tag size: 4</span><br><span class="line">  integrity: crc32c</span><br><span class="line">  device:  /dev/loop0</span><br><span class="line">  loop:    /root/rawfile</span><br><span class="line">  sector size:  512 bytes</span><br><span class="line">  interleave sectors: 32768</span><br><span class="line">  size:    258152 sectors</span><br><span class="line">  mode:    <span class="built_in">read</span>/write</span><br><span class="line">  failures: 10</span><br><span class="line">  journal size: 991232 bytes</span><br><span class="line">  journal watermark: 50%</span><br><span class="line">  journal commit time: 10000 ms</span><br><span class="line"></span><br><span class="line">$  md5sum /mnt/*</span><br><span class="line">md5sum: /mnt/infile: Input/output error <span class="comment">## error file could not be read</span></span><br><span class="line">e7eee6d6c29d2f78bbd28e14df457dc7  /mnt/testfile</span><br></pre></td></tr></table></figure>

<p>Tech preview in CentOS 8<br>Regarding support status: dm-integrity is not labeled as TechPreview, it is supported. Heavy stacks of RAID1 on top, with mdadm or LVM-raid, are not yet widely tested or recommended for production.</p>
<p><a href="https://gitlab.com/cryptsetup/cryptsetup/-/wikis/DMIntegrity" target="_blank" rel="noopener">For more DMIntegrity</a></p>

    </div>

    
    
    

      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/block/" rel="tag"><i class="fa fa-tag"></i> block</a>
              <a href="/tags/schdule/" rel="tag"><i class="fa fa-tag"></i> schdule</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2016/07/20/fault_ratio/" rel="prev" title="calculate HDD SSD fault ratio">
      <i class="fa fa-chevron-left"></i> calculate HDD SSD fault ratio
    </a></div>
      <div class="post-nav-item">
    <a href="/2016/09/04/kcptun/" rel="next" title="proxychains and kcptun">
      proxychains and kcptun <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    
  <div class="comments">
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
    </div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#Hardware"><span class="nav-number">1.</span> <span class="nav-text">Hardware</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Why-use-4K-device"><span class="nav-number">1.1.</span> <span class="nav-text">Why use 4K device</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#mpt3sas-mpt2sas-driver-parameter"><span class="nav-number">1.2.</span> <span class="nav-text">mpt3sas&#x2F;mpt2sas driver parameter</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#mpt3sas-driver-install"><span class="nav-number">1.3.</span> <span class="nav-text">mpt3sas driver install</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Driver-Build-Instructions"><span class="nav-number">1.3.1.</span> <span class="nav-text">Driver Build Instructions</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Qlogic-driver-setting"><span class="nav-number">1.4.</span> <span class="nav-text">Qlogic driver setting</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SAN-controller-setting-MD3460"><span class="nav-number">1.5.</span> <span class="nav-text">SAN controller setting MD3460</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#rebuild-feature"><span class="nav-number">2.</span> <span class="nav-text">rebuild feature</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Linux-setting"><span class="nav-number">3.</span> <span class="nav-text">Linux setting</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#block-driver"><span class="nav-number">3.1.</span> <span class="nav-text">block driver</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#block-driver-2"><span class="nav-number">3.2.</span> <span class="nav-text">block driver 2</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#parted-alignment"><span class="nav-number">3.2.1.</span> <span class="nav-text">parted alignment</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Hot-plugin-the-scsi-device"><span class="nav-number">3.2.2.</span> <span class="nav-text">Hot plugin the scsi device</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Add-the-scsi-device"><span class="nav-number">3.2.3.</span> <span class="nav-text">Add the scsi device</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Refresh-the-scsi-device"><span class="nav-number">3.2.4.</span> <span class="nav-text">Refresh the scsi device</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Remove-the-scsi-device"><span class="nav-number">3.2.5.</span> <span class="nav-text">Remove the scsi device</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#IO-schdule"><span class="nav-number">3.3.</span> <span class="nav-text">IO schdule</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#deadline-parameters"><span class="nav-number">3.4.</span> <span class="nav-text">deadline parameters</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#scsi-driver-error-handaling-EH"><span class="nav-number">4.</span> <span class="nav-text">scsi_driver error handaling (EH)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#iostat"><span class="nav-number">5.</span> <span class="nav-text">iostat</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Re-import-LVM"><span class="nav-number">6.</span> <span class="nav-text">Re-import LVM</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Advance-reformat-4Kn-SCSI-devs-to-512-Bytes-sector"><span class="nav-number">7.</span> <span class="nav-text">Advance reformat 4Kn SCSI devs to 512 Bytes sector</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#intel-nvme-switch-to-AF"><span class="nav-number">7.1.</span> <span class="nav-text">intel nvme switch to AF</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SATA-only-support-512-and-4096-Bytes"><span class="nav-number">7.2.</span> <span class="nav-text">SATA only support 512 and 4096 Bytes</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#long-data-sector"><span class="nav-number">7.3.</span> <span class="nav-text">long-data-sector</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#T10-DIF-PI"><span class="nav-number">7.3.1.</span> <span class="nav-text">T10 DIF&#x2F;PI</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#About-DIF-520-Bytes"><span class="nav-number">7.3.2.</span> <span class="nav-text">About DIF 520 Bytes</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#T10-DIX-and-PI"><span class="nav-number">7.3.3.</span> <span class="nav-text">T10 DIX and PI</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Security-erasing"><span class="nav-number">8.</span> <span class="nav-text">Security erasing</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Enable-the-blk-mq-and-scsi-mq"><span class="nav-number">9.</span> <span class="nav-text">Enable the blk_mq and scsi_mq</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#lsscsi"><span class="nav-number">10.</span> <span class="nav-text">lsscsi</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#udevinfo"><span class="nav-number">11.</span> <span class="nav-text">udevinfo</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Flush-cache-data"><span class="nav-number">12.</span> <span class="nav-text">Flush cache data</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#dev-info"><span class="nav-number">13.</span> <span class="nav-text">dev info</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#mapper-test-device"><span class="nav-number">13.1.</span> <span class="nav-text">mapper test device</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Add-remove-key"><span class="nav-number">13.2.</span> <span class="nav-text">Add&#x2F;remove key</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Back-restore-header"><span class="nav-number">13.3.</span> <span class="nav-text">Back&#x2F;restore header</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#is-luks-partition"><span class="nav-number">13.4.</span> <span class="nav-text">is luks partition</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Clean-luks-partition"><span class="nav-number">13.5.</span> <span class="nav-text">Clean luks partition</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Why-Trim"><span class="nav-number">14.</span> <span class="nav-text">Why Trim</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Openzfs-on-linux"><span class="nav-number">14.1.</span> <span class="nav-text">Openzfs on linux</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Trim-patch-for-ZOL"><span class="nav-number">14.2.</span> <span class="nav-text">Trim patch for ZOL</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Mdadm"><span class="nav-number">14.3.</span> <span class="nav-text">Mdadm</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#LSI-Check-Interoperability-and-Compatibility"><span class="nav-number">14.4.</span> <span class="nav-text">LSI Check Interoperability and Compatibility</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#HP-Raid-support"><span class="nav-number">14.5.</span> <span class="nav-text">HP Raid support</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Re-assign-bad-block"><span class="nav-number">15.</span> <span class="nav-text">Re-assign bad block</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#linux-block-integrity"><span class="nav-number">16.</span> <span class="nav-text">linux block integrity</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#test"><span class="nav-number">16.1.</span> <span class="nav-text">test</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Ginger"
      src="/img/logo-4-blog.png">
  <p class="site-author-name" itemprop="name">Ginger</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">50</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">19</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">60</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ginger</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
      <span class="post-meta-item-text">Symbols count total: </span>
    <span title="Symbols count total">809k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">Reading time total &asymp;</span>
    <span title="Reading time total">12:15</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.6.0
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://b946c5a0bf547c89.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>
<script>
  NexT.utils.loadComments(document.querySelector('#disqus_thread'), () => {
    if (window.DISQUS) {
      DISQUS.reset({
        reload: true,
        config: {page: {
            url: "http://yoursite.com/2016/08/10/block_device/",
            identifier: "2016/08/10/block_device/",
            title: "The block device"
          }
        }
      });
    } else {
      var d = document, s = d.createElement('script');
      s.src = 'https://b946c5a0bf547c89.disqus.com/embed.js';
      s.setAttribute('data-timestamp', '' + +new Date());
      (d.head || d.body).appendChild(s);
    }
  });
</script>

</body>
</html>
