<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('http://yoursite.com').hostname,
    root: '/',
    scheme: 'Muse',
    version: '7.6.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":true,"preload":true},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta name="description" content="First questionDoes the ring buffer in ethernet NIC or it ‘s just server memory ?Yes, NIC has the microprocess and system memory, but it’s not ring buffer in linux High end ethernet cards(eg: Mellanox)">
<meta property="og:type" content="article">
<meta property="og:title" content="linux nic">
<meta property="og:url" content="http://yoursite.com/2018/07/12/nic/index.html">
<meta property="og:site_name" content="b946c5a0bf547c89">
<meta property="og:description" content="First questionDoes the ring buffer in ethernet NIC or it ‘s just server memory ?Yes, NIC has the microprocess and system memory, but it’s not ring buffer in linux High end ethernet cards(eg: Mellanox)">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://yoursite.com/img/ring-buffer.png">
<meta property="og:image" content="http://yoursite.com/img/2012110119582618-tcp-reception.png">
<meta property="og:image" content="http://yoursite.com/img/2012110119593557-tcp-transmission.png">
<meta property="article:published_time" content="2018-07-11T18:29:15.000Z">
<meta property="article:modified_time" content="2020-01-05T14:56:29.760Z">
<meta property="article:author" content="Ginger">
<meta property="article:tag" content="nic">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/img/ring-buffer.png">

<link rel="canonical" href="http://yoursite.com/2018/07/12/nic/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>linux nic | b946c5a0bf547c89</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">b946c5a0bf547c89</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">My Silent Hill</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="Searching..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/12/nic/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/img/logo-4-blog.png">
      <meta itemprop="name" content="Ginger">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="b946c5a0bf547c89">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          linux nic
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-07-12 02:29:15" itemprop="dateCreated datePublished" datetime="2018-07-12T02:29:15+08:00">2018-07-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-01-05 22:56:29" itemprop="dateModified" datetime="2020-01-05T22:56:29+08:00">2020-01-05</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hardware/" itemprop="url" rel="index">
                    <span itemprop="name">hardware</span>
                  </a>
                </span>
            </span>

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2018/07/12/nic/#comments" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/07/12/nic/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>25k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>22 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h3 id="First-question"><a href="#First-question" class="headerlink" title="First question"></a>First question</h3><p>Does the ring buffer in ethernet NIC or it ‘s just server memory ?<br>Yes, NIC has the microprocess and system memory, but it’s not ring buffer in linux</p>
<p>High end ethernet cards(eg: Mellanox) will almost certainly have their own memory and microprocessors to offload work from the rest of the computer.<br>BTW: eg: if tcp stack offload by NIC and bypass kernel that means the ring buffer in NIC.</p>
<p>Low end ethernet cards may not have their own onboard memory or microprocessors, and will use the host system’s resources to handle network traffic.<br>BTW: I think if you NIC adapter could not offload anything, that means all packages will process by linux, some low end ethernet cards could bypass kernel too, could use direct memory access for some of IO</p>
<p>Infiniband cards on the other hand will tend to have their own onboard processors but no onboard memory, and will use direct memory access for all IO.</p>
<p><a href="https://stackoverflow.com/questions/17154759/how-much-memory-does-a-common-nic-have" target="_blank" rel="noopener">reference</a></p>
<a id="more"></a>

<h4 id="What-‘s-the-ring-buffer"><a href="#What-‘s-the-ring-buffer" class="headerlink" title="What ‘s the ring buffer"></a>What ‘s the ring buffer</h4><p><a href="https://www.ibm.com/support/knowledgecenter/en/SSQPD3_2.6.0/com.ibm.wllm.doc/nicringbuffers.html" target="_blank" rel="noopener">Ring buffers on the NIC are important to handle bursts of incoming packets especially if there is some delay when the hardware interrupt handler schedules the packet receiving software interrupt (softirq). NIC ring buffer sizes vary per NIC vendor and NIC grade (that is, server or desktop). By increasing the Rx/Tx ring buffer size as shown below, you can decrease the probability of discarding packets in the NIC during a scheduling delay. The tool used to change ring buffer settings is the Linux utility, ethtool.</a></p>
<h4 id="Linux-network-receive-data-work-flow"><a href="#Linux-network-receive-data-work-flow" class="headerlink" title="Linux network receive data work flow"></a><a href="https://blog.packagecloud.io/eng/2016/06/22/monitoring-tuning-linux-networking-stack-receiving-data/" target="_blank" rel="noopener">Linux network receive data work flow</a></h4><p><a href="https://ylgrgyq.github.io/2017/07/23/linux-receive-packet-1/" target="_blank" rel="noopener">reference2</a><br><img src="/img/ring-buffer.png" alt=""><br><img src="/img/2012110119582618-tcp-reception.png" alt=""><br><img src="/img/2012110119593557-tcp-transmission.png" alt=""></p>
<ol>
<li><p>Driver is loaded and initialized.</p>
<ul>
<li>Kernel malloc a special kernel memory regions for NIC to receive/transmit the network packets<ul>
<li>struct sk_buff is the memory interface for netowrk data<ul>
<li><a href="http://elixir.free-electrons.com/linux/v4.4/source/include/linux/skbuff.h#L706" target="_blank" rel="noopener">sk_buff has the point to these memory</a>, Ring buffer just store packet descriptor one by one</li>
<li>There are two status for ring buffer: “used” or “ready” <ul>
<li>ready means (the null descriptor) and it point a free sk_buff”<ul>
<li>Linux malloc system memory —mapping—&gt; ring buffer queue ( interface:struct sk_buff, netdev_alloc_skb - allocate an skbuff for rx on a specific device ) <a href="https://elixir.bootlin.com/linux/v4.4/source/include/linux/skbuff.h#L706" target="_blank" rel="noopener">source code</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Packet arrives at the NIC from the network.</p>
</li>
<li><p>Packet is copied (via DMA)the data to a ring buffer in kernel memory</p>
<ul>
<li>DMA just get data from NIC<ul>
<li>Got the the next ready descriptor, and save the data to the descriptor,the descriptor point the memory regions(sk_buff), and modify the ready descriptor to “used”</li>
<li>It ‘s a FIFO queue</li>
</ul>
</li>
<li>NIC data —-DMA—-&gt; next ready packet descriptor (The default queuing discipline to use for network devices.)</li>
</ul>
</li>
</ol>
<ol start="4">
<li><p>NIC generate the hardware interrupt to let the system know(trigger another software interrupt) a packet is in memory.</p>
<ul>
<li>If single packet trigger once IRQ to CPU, it must be exhaust a lot of CPU resources and it ‘s inefficiency</li>
<li>the kernel begin to run interrupt handler(driver register)</li>
</ul>
</li>
<li><p>Driver calls into NAPI to start a poll loop if one was not running already.</p>
<ul>
<li>Create New API(NAPI) to merge IRQs, to reduce IRQ times</li>
<li>The driver ‘s interrupt handeler use the napi_schedule trigger softirq(<a href="http://elixir.free-electrons.com/linux/v4.4/source/net/core/dev.c#L3204" target="_blank" rel="noopener">NET_RX_SOFTIRQ</a> to wake up NAPI subsystem</li>
</ul>
</li>
<li><p>ksoftirqd processes run on each CPU on the system. They are registered at boot time. The ksoftirqd processes pull packets off the ring buffer by calling the NAPI poll function that the device driver registered during initialization.</p>
</li>
<li><p>Memory regions in the ring buffer that have had network data written to them are unmapped.</p>
</li>
<li><p>Data that was DMA’d into memory is passed up the networking layer as an ‘skb’ for more processing.</p>
<ul>
<li>DMA get finish —-&gt; trigger the hardware interrupt (IRQ) let CPU receive the data —-&gt; if not support NAPI, one irq ,got one frame with single irq ?</li>
<li>DMA get finish —-&gt; trigger the hardware interrupt (IRQ) let CPU receive the data —-&gt; support NAPI (driver support), merge IRQ to reduce CPU loading    </li>
</ul>
</li>
<li><p>The softirq handler function net_rx_action will call the NAPI poll function to harvest packets (sk_buff).</p>
<ul>
<li><a href="http://elixir.free-electrons.com/linux/v4.4/source/drivers/net/ethernet/intel/igb/igb_main.c#L6361" target="_blank" rel="noopener">What ‘s the poll doing</a> ?<ul>
<li>Read out sk_buff from ring buffer </li>
<li>Check sk_buff, if single frame in multiple sk_buff, merge them</li>
<li>Deliver these network data frames to the upper-layer protocal from the queues<ul>
<li>Clear sk_buff, reset ring buff to ready</li>
<li>Update kernel/driver statistics , receive how many packages , bytes</li>
</ul>
</li>
<li>If no data or if trigger net.core.netdev_budget(packages numbers) or netdev_budget_usecs(timeout), exit the poll</li>
</ul>
</li>
</ul>
</li>
<li><p>Driver will disable the NIC IRQ, make sure will not received the new IRQ before poll finish all data</p>
</li>
<li><p>After poll receive all packegs, the NIC driver will re-enable NIC interrupts again and disable NAPI subsystem(napi_complete_done), exit pollng, NAPI subsystem will be disable, re-enable  NIC IRQ</p>
</li>
<li><p>Go to 3</p>
</li>
</ol>
<p>I guess, NIC transfer data by frame, and the frame has be splitted in sk_buff</p>
<h4 id="The-kernel-parameters"><a href="#The-kernel-parameters" class="headerlink" title="The kernel parameters"></a><a href="https://github.com/leandromoreira/linux-network-performance-parameters/blob/master/README.md" target="_blank" rel="noopener">The kernel parameters</a></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sysctl net.core.default_qdisc</span><br><span class="line">net.core.default_qdisc &#x3D; pfifo_fast #default fq</span><br></pre></td></tr></table></figure>
<p>default_qdisc is the default queuing discipline to use for network devices<br>tc -s qdisc ls dev ethX</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sysctl net.core.netdev_budget_usecs # default 2000</span><br></pre></td></tr></table></figure>
<p>netdev_budget_usecs maximum number of microseconds in one NAPI polling cycle. Polling will exit when either netdev_budget_usecs have elapsed during the poll cycle or the number of packets processed reaches netdev_budget</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sysctl net.core.netdev_budget # default 300</span><br></pre></td></tr></table></figure>
<p>netdev_budget is the maximum number of packets taken from all interfaces in one polling cycle (NAPI poll). In one polling cycle interfaces which are registered to polling are probed in a round-robin manner. Also, a polling cycle may not exceed netdev_budget_usecs microseconds, even if netdev_budget has not been exhausted.</p>
<p>$ cat /proc/net/sockstat<br>sockets: used 911<br>TCP: inuse 7 orphan 0 tw 0 alloc 11 mem 2<br>UDP: inuse 6 mem 1<br>UDPLITE: inuse 0<br>RAW: inuse 0<br>FRAG: inuse 0 memory 0</p>
<h4 id="Socket-buffer"><a href="#Socket-buffer" class="headerlink" title="Socket buffer"></a>Socket buffer</h4><p>Each network socket is allocated a send buffer for outbound packets and a receive socket for inbound packets. These buffers are assigned a default size that depends on parameters of the operating system<br>In linux<br>receive<br>net.core.rmem_max<br>net.core.rmem_default </p>
<p>Sender<br>net.core.wmem_max<br>net.core.wmem_default </p>
<h5 id="sysctl-w-net-core-netdev-budget-2000"><a href="#sysctl-w-net-core-netdev-budget-2000" class="headerlink" title="sysctl -w net.core.netdev_budget=2000"></a>sysctl -w net.core.netdev_budget=2000</h5><p>Maximum number of packets taken from all interfaces in one polling cycle (NAPI poll).<br>In one polling cycle interfaces which are registered to polling are probed in a round-robin manner. Also, a polling cycle may not exceed netdev_budget_usecs microseconds, even if netdev_budget has not been exhausted.</p>
<h6 id="netdev-budget-usecs"><a href="#netdev-budget-usecs" class="headerlink" title="netdev_budget_usecs"></a>netdev_budget_usecs</h6><p>Maximum number of microseconds in one NAPI polling cycle. Polling will exit when either netdev_budget_usecs have elapsed during the poll cycle or the number of packets processed reaches netdev_budget.</p>
<h5 id="netdev-max-backlog"><a href="#netdev-max-backlog" class="headerlink" title="netdev_max_backlog"></a>netdev_max_backlog</h5><p>Maximum number of  packets,  queued  on  the  INPUT  side, when the interface receives packets faster than kernel can process them.<br>Sets the maximum number of packets allowed to queue when a particular interface receives packets faster than the kernel can process them.</p>
<h5 id="Enabling-flow-limits-and-tuning-flow-limit-hash-table-size"><a href="#Enabling-flow-limits-and-tuning-flow-limit-hash-table-size" class="headerlink" title="Enabling flow limits and tuning flow limit hash table size"></a>Enabling flow limits and tuning flow limit hash table size</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">$ sysctl -w net.core.flow_limit_table_len=8192</span><br><span class="line">The value is only consulted when a new table is allocated. Modifying</span><br><span class="line">it does not update active tables.</span><br><span class="line"></span><br><span class="line">$ cat /proc/sys/net/core/flow_limit_cpu_bitmap</span><br><span class="line">00000</span><br><span class="line"></span><br><span class="line"><span class="comment"># set a bitmask </span></span><br><span class="line"><span class="built_in">echo</span> f &gt; /proc/sys/net/core/flow_limit_cpu_bitmap</span><br><span class="line"></span><br><span class="line">Per-flow rate is calculated by hashing each packet into a hashtable</span><br><span class="line">bucket and incrementing a per-bucket counter. The <span class="built_in">hash</span> <span class="keyword">function</span> is</span><br><span class="line">the same that selects a CPU <span class="keyword">in</span> RPS, but as the number of buckets can</span><br><span class="line">be much larger than the number of CPUs, flow <span class="built_in">limit</span> has finer-grained</span><br><span class="line">identification of large flows and fewer <span class="literal">false</span> positives. The default</span><br><span class="line">table has 4096 buckets. This value can be modified through sysctl</span><br><span class="line"></span><br><span class="line">Flow <span class="built_in">limit</span> is useful on systems with many concurrent connections,</span><br><span class="line"><span class="built_in">where</span> a single connection taking up 50% of a CPU indicates a problem.</span><br><span class="line">In such environments, <span class="built_in">enable</span> the feature on all CPUs that handle</span><br><span class="line">network rx interrupts (as <span class="built_in">set</span> <span class="keyword">in</span> /proc/irq/N/smp_affinity).</span><br><span class="line"></span><br><span class="line">The feature depends on the input packet queue length to exceed</span><br><span class="line">the flow <span class="built_in">limit</span> threshold (50%) + the flow <span class="built_in">history</span> length (256).</span><br><span class="line">Setting net.core.netdev_max_backlog to either 1000 or 10000</span><br><span class="line">performed well <span class="keyword">in</span> experiments.</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">$ ethtool -l enp1s0f1<span class="string">"</span></span><br><span class="line"><span class="string">Channel parameters for enp1s0f1:</span></span><br><span class="line"><span class="string">Pre-set maximums:</span></span><br><span class="line"><span class="string">RX:		0</span></span><br><span class="line"><span class="string">TX:		0</span></span><br><span class="line"><span class="string">Other:		1</span></span><br><span class="line"><span class="string">Combined:	63</span></span><br><span class="line"><span class="string">Current hardware settings:</span></span><br><span class="line"><span class="string">RX:		0</span></span><br><span class="line"><span class="string">TX:		0</span></span><br><span class="line"><span class="string">Other:		1</span></span><br><span class="line"><span class="string">Combined:	4 # 4 cores Xeon E3 CPU</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">$ ethtool -L enp1s0f1 combined 8  #combined means tx and rx</span></span><br><span class="line"><span class="string">$ ethtool -L enp1s0f1 rx 8</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#Does NIC support ring buffer multi queues</span></span><br><span class="line"><span class="string">$ ethtool -g em1</span></span><br><span class="line"><span class="string">Ring parameters for em1:</span></span><br><span class="line"><span class="string">Pre-set maximums:</span></span><br><span class="line"><span class="string">RX:		4078</span></span><br><span class="line"><span class="string">RX Mini:	0</span></span><br><span class="line"><span class="string">RX Jumbo:	0</span></span><br><span class="line"><span class="string">TX:		4078</span></span><br><span class="line"><span class="string">$ Current hardware settings:</span></span><br><span class="line"><span class="string">RX:		1024</span></span><br><span class="line"><span class="string">RX Mini:	0</span></span><br><span class="line"><span class="string">RX Jumbo:	0</span></span><br><span class="line"><span class="string">TX:		4078</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ethtool -G em1 rx 4078 tx 4078</span></span><br></pre></td></tr></table></figure>
<h3 id="NIC-Offload"><a href="#NIC-Offload" class="headerlink" title="NIC Offload"></a><a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/performance_tuning_guide/network-nic-offloads" target="_blank" rel="noopener">NIC Offload</a></h3><h4 id="Generic-Receive-Offloading-replace-Large-receive-offload-https-lwn-net-Articles-358910"><a href="#Generic-Receive-Offloading-replace-Large-receive-offload-https-lwn-net-Articles-358910" class="headerlink" title="[Generic Receive Offloading replace Large receive offload] (https://lwn.net/Articles/358910/)"></a>[Generic Receive Offloading replace Large receive offload] (<a href="https://lwn.net/Articles/358910/" target="_blank" rel="noopener">https://lwn.net/Articles/358910/</a>)</h4><p><a href="https://en.wikipedia.org/wiki/Large_receive_offload" target="_blank" rel="noopener">Large receive offload(LRO)</a><br> It works by aggregating multiple incoming packets from a single stream into a larger buffer before they are passed higher up the networking stack, thus reducing the number of packets that have to be processed. Linux implementations generally use LRO in conjunction with the New API (NAPI) to also reduce the number of interrupts.</p>
<p>LRO Uses the TCP protocol. All incoming packets are re-segmented as they are received, reducing the number of segments the system has to process. They can be merged either in the driver or using the NIC. A problem with LRO is that it tends to resegment all incoming packets, often ignoring differences in headers and other information which can cause errors. It is generally not possible to use LRO when IP forwarding is enabled.</p>
<p>GRO Uses either the TCP or UDP protocols. GRO is more rigorous than LRO when resegmenting packets. For example it checks the MAC headers of each packet, which must match, only a limited number of TCP or IP headers can be different, and the TCP timestamps must match. Resegmenting can be handled by either the NIC or the GSO code.</p>
<h4 id="TCP-Segmentation-Offload-TSO"><a href="#TCP-Segmentation-Offload-TSO" class="headerlink" title="TCP Segmentation Offload (TSO)"></a>TCP Segmentation Offload (TSO)</h4><p>Uses the TCP protocol to send large packets. Uses the NIC to handle segmentation, and then adds the TCP, IP and data link layer protocol headers to each segment.</p>
<h4 id="UDP-Fragmentation-Offload-UFO"><a href="#UDP-Fragmentation-Offload-UFO" class="headerlink" title="UDP Fragmentation Offload (UFO)"></a>UDP Fragmentation Offload (UFO)</h4><p>Uses the UDP protocol to send large packets. Uses the NIC to handle IP fragmentation into MTU sized packets for large UDP datagrams.</p>
<h4 id="Generic-Segmentation-Offload-GSO"><a href="#Generic-Segmentation-Offload-GSO" class="headerlink" title="Generic Segmentation Offload (GSO)"></a>Generic Segmentation Offload (GSO)</h4><p>Uses the TCP or UDP protocol to send large packets. If the NIC cannot handle segmentation/fragmentation, GSO performs the same operations, bypassing the NIC hardware. This is achieved by delaying segmentation until as late as possible, for example, when the packet is processed by the device driver.</p>
<h4 id="RECEIVE-SIDE-SCALING-RSS"><a href="#RECEIVE-SIDE-SCALING-RSS" class="headerlink" title="RECEIVE-SIDE SCALING (RSS)"></a>RECEIVE-SIDE SCALING (RSS)</h4><p>Receive-Side Scaling (RSS), also known as multi-queue receive, distributes network receive processing across several hardware-based receive queues, allowing inbound network traffic to be processed by multiple CPUs. RSS can be used to relieve bottlenecks in receive interrupt processing caused by overloading a single CPU, and to reduce network latency.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">$ ethtool --show-rxfh-indir p4p1</span><br><span class="line">$ ethtool -x p4p1 </span><br><span class="line"><span class="comment">## You can set priority for each queue.</span></span><br><span class="line">RX flow <span class="built_in">hash</span> indirection table <span class="keyword">for</span> p4p1 with 48 RX ring(s):</span><br><span class="line">    0:      0     1     2     3     4     5     6     7 </span><br><span class="line">    8:      8     9    10    11    12    13    14    15</span><br><span class="line">   16:     16    17    18    19    20    21    22    23</span><br><span class="line">   24:     24    25    26    27    28    29    30    31</span><br><span class="line">   32:     32    33    34    35    36    37    38    39</span><br><span class="line">   40:     40    41    42    43    44    45    46    47</span><br><span class="line">   48:      0     1     2     3     4     5     6     7</span><br><span class="line">   56:      8     9    10    11    12    13    14    15</span><br><span class="line">   64:     16    17    18    19    20    21    22    23</span><br><span class="line">   72:     24    25    26    27    28    29    30    31</span><br><span class="line">   80:     32    33    34    35    36    37    38    39</span><br><span class="line">   88:     40    41    42    43    44    45    46    47</span><br><span class="line">   96:      0     1     2     3     4     5     6     7</span><br><span class="line">  104:      8     9    10    11    12    13    14    15</span><br><span class="line">  112:     16    17    18    19    20    21    22    23</span><br><span class="line">  120:     24    25    26    27    28    29    30    31</span><br><span class="line"><span class="comment">### 16 x 8 = 128, total 128 value, that means indirection table = 128, total 48 RX rings</span></span><br><span class="line"><span class="comment">### eg: line "96:" second field(1), means 98th hash data equal 2, the data will go to second queue</span></span><br><span class="line"><span class="comment">### ethtool -X eth0 weight 6 5 4 3 2 1 .... , you can set 48 x weights, 48 data sum will not large than 128</span></span><br><span class="line"></span><br><span class="line">$ ethtool --show-rxfh-indir p4p1 rx-flow-hash tcp4</span><br><span class="line">RX flow <span class="built_in">hash</span> indirection table <span class="keyword">for</span> p4p1 with 48 RX ring(s):</span><br><span class="line">    0:      0     1     2     3     4     5     6     7</span><br><span class="line">    8:      8     9    10    11    12    13    14    15</span><br><span class="line">   16:     16    17    18    19    20    21    22    23</span><br><span class="line">   24:     24    25    26    27    28    29    30    31</span><br><span class="line">   32:     32    33    34    35    36    37    38    39</span><br><span class="line">   40:     40    41    42    43    44    45    46    47</span><br><span class="line">   48:      0     1     2     3     4     5     6     7</span><br><span class="line">   56:      8     9    10    11    12    13    14    15</span><br><span class="line">   64:     16    17    18    19    20    21    22    23</span><br><span class="line">   72:     24    25    26    27    28    29    30    31</span><br><span class="line">   80:     32    33    34    35    36    37    38    39</span><br><span class="line">   88:     40    41    42    43    44    45    46    47</span><br><span class="line">   96:      0     1     2     3     4     5     6     7</span><br><span class="line">  104:      8     9    10    11    12    13    14    15</span><br><span class="line">  112:     16    17    18    19    20    21    22    23</span><br><span class="line">  120:     24    25    26    27    28    29    30    31</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#modify hash behavior</span></span><br><span class="line"><span class="comment">#src IP, dst IP, src Port, dst Port (sdfn)</span></span><br><span class="line">To include UDP port numbers <span class="keyword">in</span> RSS hashing run(4-tuple):</span><br><span class="line">$ ethtool -N eth1 rx-flow-hash udp4 sdfn</span><br><span class="line"></span><br><span class="line">To exclude UDP port numbers from RSS hashing run(2-tuple):</span><br><span class="line">$ ethtool -N eth1 rx-flow-hash udp4 sd</span><br><span class="line"></span><br><span class="line">To display UDP hashing current configuration run:</span><br><span class="line">$ ethtool -n eth1 rx-flow-hash udp4</span><br><span class="line"></span><br><span class="line"><span class="comment"># use --set-rxfh-indir modify the parameters</span></span><br><span class="line">`</span><br></pre></td></tr></table></figure>
<p>Receive Packet Steering (RPS) is similar to RSS in that it is used to direct packets to specific CPUs for processing. However, RPS is implemented at the software level, and helps to prevent the hardware queue of a single network interface card from becoming a bottleneck in network traffic.<br>Does the all cpu cores share a  hardware-based receive queues ?</p>
<h4 id="Receive-Flow-Steering-ntuple-RFS"><a href="#Receive-Flow-Steering-ntuple-RFS" class="headerlink" title="Receive Flow Steering, (ntuple,RFS)"></a><a href="https://wiki.freebsd.org/201305DevSummit/NetworkReceivePerformance/ComparingMutiqueueSupportLinuxvsFreeBSD" target="_blank" rel="noopener">Receive Flow Steering, (ntuple,RFS)</a></h4><p>RSS transmit diff the network frame to diff cpu core, the userspace application not in this cpu core, move data to cache for share, and avoid cache bouncing<br>RPS/ntuple will to optimze the process</p>
<p>Receive Flow Steering (RFS) extends RPS/RSS behavior to increase the CPU cache hit rate and thereby reduce network latency. Where RPS forwards packets based solely on queue length, RFS uses the RPS backend to calculate the most appropriate CPU, then forwards packets based on the location of the application consuming the packet. This increases CPU cache efficiency.</p>
<ul>
<li>RFS software<ul>
<li>RPS does not increase the hardware interrupt rate of the network device.</li>
</ul>
</li>
<li>ntuple hardware<ul>
<li>EP, Externally Programed<ul>
<li>Custom policy<ul>
<li>Match the policy, move the frame to the transmit CPU core queue </li>
<li>or match the policy/action, move to special queue for route/firewall</li>
</ul>
</li>
</ul>
</li>
<li>ATR, Automated Application Targeting Routing</li>
</ul>
</li>
</ul>
<p>There’s generic flow steering rule configuration interface on ethtool, called RX NFC.<br>Accelerated RFS configures Flow Steering automatically, RX NFC offers manual configuration feature to user.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">$ lshw -c network -businfo</span><br><span class="line">Bus info          Device      Class          Description</span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">pci@0000:04:00.0  em1         network        NetXtreme BCM5720 2-port Gigabit Ethernet PCIe</span><br><span class="line">pci@0000:04:00.1  em2         network        NetXtreme BCM5720 2-port Gigabit Ethernet PCIe</span><br><span class="line">pci@0000:65:00.0  p2p1        network        Ethernet 10G 2P X520 Adapter</span><br><span class="line">pci@0000:65:00.1  p2p2        network        Ethernet 10G 2P X520 Adapter</span><br><span class="line">                  bond0       network        Ethernet interface</span><br><span class="line">#To specify that all traffic from 10.23.4.6 to 10.23.4.18 be placed in queue 4, issue this command:</span><br><span class="line">$ ethtool --config-ntuple flow-type tcp4 src-ip 10.23.4.6 dst-ip 10.23.4.18 action 4</span><br><span class="line"></span><br><span class="line">#Forwards to queue 2 all IPv4 TCP traffic from 192.168.10.1:2000 that is going to 192.168.10.2:2001, placing the filter at position 33 of the Perfect-Match filter table (and overwriting any rule currently in that position):</span><br><span class="line">$ ethtool --config-ntuple &lt;interface name&gt; flow-type tcp4 src-ip 192.168.10.1 dst-ip 192.168.10.2 src-port 2000 dst-port 2001 action 2 loc 33</span><br><span class="line"></span><br><span class="line">#Drops all UDP packets from 10.4.83.2:</span><br><span class="line">$ ethtool --config-ntuple flow-type udp4 src-ip 10.4.82.2 action -1</span><br><span class="line">#Note: The VLAN field is not a supported filter with the i40e driver (Intel Ethernet Controller XL710 and Intel Ethernet Controller X710 NICs).</span><br><span class="line">#For more information and options, see the ethtool man page documentation on the -U, -N, or --config-ntuple option.</span><br><span class="line"></span><br><span class="line"># List</span><br><span class="line">$ ethtool --show-ntuple p2p1</span><br><span class="line">10 RX rings available</span><br><span class="line">Total 0 rules</span><br><span class="line"></span><br><span class="line"># Remove </span><br><span class="line">$ ethtool --config-ntuple &lt;interface name&gt; delete N</span><br><span class="line"></span><br><span class="line">$ ethtool -K eth0 ntuple on</span><br><span class="line">$ ethtool -k eth0|grep ntuple</span><br><span class="line">ntuple-filters: on</span><br><span class="line">$ ethtool --config-nfc ix00 flow-type tcp4 src-ip 10.0.0.1 dst-ip 10.0.0.2 src-port 10000 dst-port 10001 action 6</span><br><span class="line">Added rule with ID 2045</span><br><span class="line">$ ethtool --show-nfc ix00</span><br><span class="line">12 RX rings available</span><br><span class="line">Total 1 rules</span><br><span class="line"></span><br><span class="line">Filter: 2045</span><br><span class="line">     Rule Type: TCP over IPv4</span><br><span class="line">     Src IP addr: 10.0.0.1 mask: 0.0.0.0</span><br><span class="line">     Dest IP addr: 10.0.0.2 mask: 0.0.0.0</span><br><span class="line">     TOS: 0x0 mask: 0xff</span><br><span class="line">     Src port: 10000 mask: 0x0</span><br><span class="line">     Dest port: 10001 mask: 0x0</span><br><span class="line">     VLAN EtherType: 0x0 mask: 0xffff</span><br><span class="line">     VLAN: 0x0 mask: 0xffff</span><br><span class="line">     User-defined: 0x0 mask: 0xffffffffffffffff</span><br><span class="line">     Action: Direct to queue 6</span><br><span class="line">$ ethtool --config-ntuple eth0  rx-flow-hash tcp4 sdfn</span><br><span class="line">$ ethtool --show-ntuple eth0 rx-flow-hash tcp4</span><br></pre></td></tr></table></figure>

<h5 id="intel-82599"><a href="#intel-82599" class="headerlink" title="intel 82599"></a>intel 82599</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">$ ethtool -k enp131s0f1</span><br><span class="line">Features <span class="keyword">for</span> enp131s0f1:</span><br><span class="line">rx-checksumming: on</span><br><span class="line">tx-checksumming: on</span><br><span class="line">	tx-checksum-ipv4: off [fixed]</span><br><span class="line">	tx-checksum-ip-generic: on</span><br><span class="line">	tx-checksum-ipv6: off [fixed]</span><br><span class="line">	tx-checksum-fcoe-crc: on [fixed]</span><br><span class="line">	tx-checksum-sctp: on</span><br><span class="line">scatter-gather: on</span><br><span class="line">	tx-scatter-gather: on</span><br><span class="line">	tx-scatter-gather-fraglist: off [fixed]</span><br><span class="line">tcp-segmentation-offload: on</span><br><span class="line">	tx-tcp-segmentation: on</span><br><span class="line">	tx-tcp-ecn-segmentation: off [fixed]</span><br><span class="line">	tx-tcp6-segmentation: on</span><br><span class="line">	tx-tcp-mangleid-segmentation: off</span><br><span class="line">udp-fragmentation-offload: off [fixed]</span><br><span class="line">generic-segmentation-offload: on</span><br><span class="line">generic-receive-offload: on</span><br><span class="line">large-receive-offload: off</span><br><span class="line">rx-vlan-offload: on</span><br><span class="line">tx-vlan-offload: on</span><br><span class="line">ntuple-filters: off</span><br><span class="line">receive-hashing: on</span><br><span class="line">highdma: on [fixed]</span><br><span class="line">rx-vlan-filter: on</span><br><span class="line">vlan-challenged: off [fixed]</span><br><span class="line">tx-lockless: off [fixed]</span><br><span class="line">netns-local: off [fixed]</span><br><span class="line">tx-gso-robust: off [fixed]</span><br><span class="line">tx-fcoe-segmentation: on [fixed]</span><br><span class="line">tx-gre-segmentation: on</span><br><span class="line">tx-ipip-segmentation: on</span><br><span class="line">tx-sit-segmentation: on</span><br><span class="line">tx-udp_tnl-segmentation: on</span><br><span class="line">tx-mpls-segmentation: off [fixed]</span><br><span class="line">fcoe-mtu: off [fixed]</span><br><span class="line">tx-nocache-copy: off</span><br><span class="line">loopback: off [fixed]</span><br><span class="line">rx-fcs: off [fixed]</span><br><span class="line">rx-all: off</span><br><span class="line">tx-vlan-stag-hw-insert: off [fixed]</span><br><span class="line">rx-vlan-stag-hw-parse: off [fixed]</span><br><span class="line">rx-vlan-stag-filter: off [fixed]</span><br><span class="line">busy-poll: on [fixed]</span><br><span class="line">tx-gre-csum-segmentation: on</span><br><span class="line">tx-udp_tnl-csum-segmentation: on</span><br><span class="line">tx-gso-partial: on</span><br><span class="line">tx-sctp-segmentation: off [fixed]</span><br><span class="line">l2-fwd-offload: off</span><br><span class="line">hw-tc-offload: off [fixed]</span><br></pre></td></tr></table></figure>

<h5 id="Mellanox-ConnectX-4-Lx"><a href="#Mellanox-ConnectX-4-Lx" class="headerlink" title="Mellanox ConnectX-4 Lx"></a>Mellanox ConnectX-4 Lx</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">ethtool -k enp131s0f1</span><br><span class="line">Features <span class="keyword">for</span> enp131s0f1:</span><br><span class="line">rx-checksumming: on</span><br><span class="line">tx-checksumming: on</span><br><span class="line">	tx-checksum-ipv4: on</span><br><span class="line">	tx-checksum-ip-generic: off [fixed]</span><br><span class="line">	tx-checksum-ipv6: on</span><br><span class="line">	tx-checksum-fcoe-crc: off [fixed]</span><br><span class="line">	tx-checksum-sctp: off [fixed]</span><br><span class="line">scatter-gather: on</span><br><span class="line">	tx-scatter-gather: on</span><br><span class="line">	tx-scatter-gather-fraglist: off [fixed]</span><br><span class="line">tcp-segmentation-offload: on</span><br><span class="line">	tx-tcp-segmentation: on</span><br><span class="line">	tx-tcp-ecn-segmentation: off [fixed]</span><br><span class="line">	tx-tcp6-segmentation: on</span><br><span class="line">	tx-tcp-mangleid-segmentation: off</span><br><span class="line">udp-fragmentation-offload: off [fixed]</span><br><span class="line">generic-segmentation-offload: on</span><br><span class="line">generic-receive-offload: on</span><br><span class="line">large-receive-offload: on</span><br><span class="line">rx-vlan-offload: on</span><br><span class="line">tx-vlan-offload: on</span><br><span class="line">ntuple-filters: off</span><br><span class="line">receive-hashing: on</span><br><span class="line">highdma: on [fixed]</span><br><span class="line">rx-vlan-filter: on</span><br><span class="line">vlan-challenged: off [fixed]</span><br><span class="line">tx-lockless: off [fixed]</span><br><span class="line">netns-local: off [fixed]</span><br><span class="line">tx-gso-robust: off [fixed]</span><br><span class="line">tx-fcoe-segmentation: off [fixed]</span><br><span class="line">tx-gre-segmentation: off [fixed]</span><br><span class="line">tx-ipip-segmentation: off [fixed]</span><br><span class="line">tx-sit-segmentation: off [fixed]</span><br><span class="line">tx-udp_tnl-segmentation: on</span><br><span class="line">tx-mpls-segmentation: off [fixed]</span><br><span class="line">fcoe-mtu: off [fixed]</span><br><span class="line">tx-nocache-copy: off</span><br><span class="line">loopback: off [fixed]</span><br><span class="line">rx-fcs: off</span><br><span class="line">rx-all: off</span><br><span class="line">tx-vlan-stag-hw-insert: off [fixed]</span><br><span class="line">rx-vlan-stag-hw-parse: off [fixed]</span><br><span class="line">rx-vlan-stag-filter: off [fixed]</span><br><span class="line">busy-poll: off [fixed]</span><br><span class="line">tx-gre-csum-segmentation: off [fixed]</span><br><span class="line">tx-udp_tnl-csum-segmentation: on</span><br><span class="line">tx-gso-partial: on</span><br><span class="line">tx-sctp-segmentation: off [fixed]</span><br><span class="line">l2-fwd-offload: off [fixed]</span><br><span class="line">hw-tc-offload: off</span><br></pre></td></tr></table></figure>

<h4 id="softnet-stat"><a href="#softnet-stat" class="headerlink" title="softnet_stat"></a><a href="https://blog.packagecloud.io/eng/2016/06/22/monitoring-tuning-linux-networking-stack-receiving-data/" target="_blank" rel="noopener">softnet_stat</a></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line">cat /proc/net/softnet_stat;</span><br><span class="line">00000797 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000</span><br><span class="line">1e391700 00000000 00000039 00000000 00000000 00000000 00000000 00000000 00000000 00000000</span><br><span class="line">e46ce530 00000000 00000010 00000000 00000000 00000000 00000000 00000000 00000000 00000000</span><br><span class="line">046aed8d 00000000 0000003f 00000000 00000000 00000000 00000000 00000000 00000000 00000000</span><br><span class="line">-----    -----    --------                                              -------  -------</span><br><span class="line">   \      \_ drop count \                                                  \        \-flow <span class="built_in">limit</span> cont</span><br><span class="line">    \_ packet count      \                                                  \-- cpu collision          </span><br><span class="line">                          \- time sequeeze</span><br><span class="line"></span><br><span class="line">Important details about /proc/net/softnet_stat:</span><br><span class="line"></span><br><span class="line">Each line of /proc/net/softnet_stat corresponds to a struct softnet_data structure, of <span class="built_in">which</span> there is 1 per CPU.</span><br><span class="line"></span><br><span class="line">The values are separated by a single space and are displayed <span class="keyword">in</span> hexadecimal</span><br><span class="line">The first value, sd-&gt;processed, is the number of network frames processed. This can be more than the total number of network frames received <span class="keyword">if</span> you are using ethernet bonding. There are cases <span class="built_in">where</span> the ethernet bonding driver will trigger network data to be re-processed, <span class="built_in">which</span> would increment the sd-&gt;processed count more than once <span class="keyword">for</span> the same packet.</span><br><span class="line"></span><br><span class="line">The second value, sd-&gt;dropped, is the number of network frames dropped because there was no room on the processing queue. More on this later.</span><br><span class="line">If second values are gorwing, improve sysctl -w net.core.netdev_max_backlog = 2000, A value over 10000 is unlikely to be very helpful.</span><br><span class="line"></span><br><span class="line">The third value, sd-&gt;time_squeeze, is (as we saw) the number of <span class="built_in">times</span> the net_rx_action loop terminated because the budget was consumed or the time <span class="built_in">limit</span> was reached, but more work could have been. Increasing the budget as explained earlier can <span class="built_in">help</span> reduce this.</span><br><span class="line">If 3rd column is growing,improve sysctl -w net.core.netdev_budget=600</span><br><span class="line">Be careful of increasing this value unless there is a very good reason. A value exceeding 1000 is unlikely to be very helpful. In fact increasing this value too much can have detrimental effect and <span class="keyword">in</span> the worse <span class="keyword">case</span> scenario lead to softirq hangs or performance problems, as the softirqs can run <span class="keyword">for</span> too long and starve other processes of CPU</span><br><span class="line"></span><br><span class="line">The next 5 values are always 0.</span><br><span class="line"></span><br><span class="line">The ninth value, sd-&gt;cpu_collision, is a count of the number of <span class="built_in">times</span> a collision occurred when trying to obtain a device lock when transmitting packets. This article is about receive, so this statistic will not be seen below.</span><br><span class="line"></span><br><span class="line">The tenth value, sd-&gt;received_rps, is a count of the number of <span class="built_in">times</span> this CPU has been woken up to process packets via an Inter-processor Interrupt</span><br><span class="line"></span><br><span class="line">The last value, flow_limit_count, is a count of the number of <span class="built_in">times</span> the flow <span class="built_in">limit</span> has been reached. Flow limiting is an optional Receive Packet Steering feature that will be examined shortly.</span><br><span class="line"></span><br><span class="line">If you decide to monitor this file and graph the results, you must be extremely careful that the ordering of these fields hasn’t changed and that the meaning of each field has been preserved. You will need to <span class="built_in">read</span> the kernel <span class="built_in">source</span> to verify this.</span><br><span class="line"></span><br><span class="line">seq_printf(seq,</span><br><span class="line">       <span class="string">"%08x %08x %08x %08x %08x %08x %08x %08x %08x %08x %08x\n"</span>,</span><br><span class="line">       sd-&gt;processed, sd-&gt;dropped, sd-&gt;time_squeeze, 0,</span><br><span class="line">       0, 0, 0, 0, /* was fastroute */</span><br><span class="line">       sd-&gt;cpu_collision, sd-&gt;received_rps, flow_limit_count);</span><br><span class="line"></span><br><span class="line"><span class="comment">#convert these data by bash</span></span><br><span class="line"></span><br><span class="line">cat ./softnet_stat.sh</span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">awk <span class="string">'BEGIN &#123;</span></span><br><span class="line"><span class="string">     t[1]="sd-&gt;processed"</span></span><br><span class="line"><span class="string">     t[2]="sd-&gt;dropped"</span></span><br><span class="line"><span class="string">     t[3]="sd-&gt;time_squeeze"</span></span><br><span class="line"><span class="string">     t[9]="sd-&gt;cpu_collision"</span></span><br><span class="line"><span class="string">     t[10]="sd-&gt;received_rps"</span></span><br><span class="line"><span class="string">     printf "%s %s %s %s %s\n",t[1],t[2],t[3],t[9],t[10];</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">   printf "%d %d %d %d %d\n", strtonum( "0x"$1 ),strtonum( "0x"$2 ),strtonum( "0x"$3 ),strtonum( "0x"$9 ),strtonum( "0x"$10 )</span></span><br><span class="line"><span class="string">&#125;'</span>  /proc/net/softnet_stat | column -t</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">$ watch -d ./softnet_stat.sh</span><br><span class="line">Every 2.0s: ./softnet_stat.sh                                                                                          Wed Jul 18 11:32:10 2018</span><br><span class="line"></span><br><span class="line">sd-&gt;processed  sd-&gt;dropped  sd-&gt;time_squeeze  sd-&gt;cpu_collision  sd-&gt;received_rps</span><br><span class="line">511952849      0            3                 0                  0</span><br><span class="line">172076174      0            0                 0                  0</span><br><span class="line">424094332      0            0                 0                  0</span><br><span class="line">202775884      0            0                 0                  0</span><br><span class="line">207782085      0            0                 0                  0</span><br><span class="line">269964983      0            1                 0                  0</span><br><span class="line">409462655      0            0                 0                  0</span><br><span class="line">253556517      0            0                 0                  0</span><br><span class="line">215071078      0            0                 0                  0</span><br><span class="line">321583328      0            0                 0                  0</span><br><span class="line">4854           0            0                 0                  0</span><br><span class="line">5438           0            0                 0                  0</span><br><span class="line">4832           0            0                 0                  0</span><br><span class="line">5124           0            0                 0                  0</span><br><span class="line">5409           0            0                 0                  0</span><br><span class="line">5512           0            0                 0                  0</span><br><span class="line">5765           0            0                 0                  0</span><br><span class="line">4915           0            0                 0                  0</span><br><span class="line">4208           0            0                 0                  0</span><br><span class="line">3617           0            0                 0                  0</span><br></pre></td></tr></table></figure>

<h3 id="why-telent-return-after-127s"><a href="#why-telent-return-after-127s" class="headerlink" title="why telent return after 127s"></a><a href="https://testerhome.com/topics/8859" target="_blank" rel="noopener">why telent return after 127s</a></h3><p>net.ipv4.tcp_syn_retries = 6</p>
<p>tcp_syn_retries - INTEGER</p>
<p>Number of times initial SYNs for an active TCP connection attempt will be retransmitted. Should not be higher than 127. Default value<br>is 6, which corresponds to 63seconds till the last retransmission with the current initial RTO of 1second. With this the final timeout for an active TCP connection attempt will happen after 127seconds.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">time telnet <span class="variable">$ip</span> <span class="variable">$port</span></span><br><span class="line"></span><br><span class="line">Trying <span class="variable">$ip</span>...</span><br><span class="line">telnet: connect to address <span class="variable">$ip</span>: Connection timed out</span><br><span class="line">telnet <span class="variable">$ip</span> <span class="variable">$port</span>  0.00s user 0.00s system 0% cpu 2:07.29 total</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">18:04:23.765507 IP <span class="variable">$ip1</span>.<span class="variable">$port1</span> &gt; <span class="variable">$ip2</span>.<span class="variable">$port2</span>: Flags [S], seq 922947731, win 29200, options [mss 1460,sackOK,TS val 13801993 ecr 0,nop,wscale 7], length 0</span><br><span class="line">18:04:24.768182 IP <span class="variable">$ip1</span>.<span class="variable">$port1</span> &gt; <span class="variable">$ip2</span>.<span class="variable">$port2</span>: Flags [S], seq 922947731, win 29200, options [mss 1460,sackOK,TS val 13802996 ecr 0,nop,wscale 7], length 0</span><br><span class="line">18:04:26.772188 IP <span class="variable">$ip1</span>.<span class="variable">$port1</span> &gt; <span class="variable">$ip2</span>.<span class="variable">$port2</span>: Flags [S], seq 922947731, win 29200, options [mss 1460,sackOK,TS val 13805000 ecr 0,nop,wscale 7], length 0</span><br><span class="line">18:04:30.780189 IP <span class="variable">$ip1</span>.<span class="variable">$port1</span> &gt; <span class="variable">$ip2</span>.<span class="variable">$port2</span>: Flags [S], seq 922947731, win 29200, options [mss 1460,sackOK,TS val 13809008 ecr 0,nop,wscale 7], length 0</span><br><span class="line">18:04:38.796205 IP <span class="variable">$ip1</span>.<span class="variable">$port1</span> &gt; <span class="variable">$ip2</span>.<span class="variable">$port2</span>: Flags [S], seq 922947731, win 29200, options [mss 1460,sackOK,TS val 13817024 ecr 0,nop,wscale 7], length 0</span><br><span class="line">18:04:54.828196 IP <span class="variable">$ip1</span>.<span class="variable">$port1</span> &gt; <span class="variable">$ip2</span>.<span class="variable">$port2</span>: Flags [S], seq 922947731, win 29200, options [mss 1460,sackOK,TS val 13833056 ecr 0,nop,wscale 7], length 0</span><br><span class="line">18:05:26.860210 IP <span class="variable">$ip1</span>.<span class="variable">$port1</span> &gt; <span class="variable">$ip2</span>.<span class="variable">$port2</span>: Flags [S], seq 922947731, win 29200, options [mss 1460,sackOK,TS val 13865088 ecr 0,nop,wscale 7], length 0</span><br><span class="line"></span><br><span class="line">18:04:23.765507</span><br><span class="line">18:04:24.768182 1s</span><br><span class="line">18:04:26.772188 2s</span><br><span class="line">18:04:30.780189 4s</span><br><span class="line">18:04:38.796205 8s</span><br><span class="line">18:04:54.828196 16s</span><br><span class="line">18:05:26.860210 32s</span><br><span class="line">06:30.98        64s</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line"><span class="comment">#net.ipv4.tcp_syn_retries = 6</span></span><br></pre></td></tr></table></figure>

<h3 id="Kernel-optimze"><a href="#Kernel-optimze" class="headerlink" title="Kernel optimze"></a>Kernel optimze</h3><p>&lt; 4.4 kernel each listener has a request queue, receive the syn package, the listener create a request for insert, &gt;=4.4 kernel the new requestfunction, use tcp ehash table, reduce the listener lock to compete</p>
<h3 id="Enable-VT-D-and-VT-in-BIOS"><a href="#Enable-VT-D-and-VT-in-BIOS" class="headerlink" title="Enable VT-D and VT in BIOS"></a>Enable VT-D and VT in BIOS</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grubby --update-kernel=ALL --args=<span class="string">'intel_iommu=on'</span></span><br></pre></td></tr></table></figure>

<p><code>Please enable sr-iov in BIOS setting with the NIC</code></p>
<h4 id="sriov-doc"><a href="#sriov-doc" class="headerlink" title="sriov doc"></a><a href="https://www.intel.com/content/dam/www/public/us/en/documents/technology-briefs/xl710-sr-iov-config-guide-gbe-linux-brief.pdf" target="_blank" rel="noopener">sriov doc</a></h4><p>On Linux Kernel version 3.8.x and above, the maximum number of VFs supported by the adapter can be queried by reading the sriov_totalvfs parameter via sysfs interface. </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">$ cat /sys/class/net/ens5f0/device/sriov_totalvfs</span><br><span class="line">64</span><br><span class="line">$ cat /sys/class/net/ens5f0/device/sriov_numvfs</span><br><span class="line">4</span><br><span class="line">$ lspci | grep Virtual</span><br><span class="line">03:02.0 Ethernet controller: Intel Corporation XL710/X710 Virtual Function (rev 02)</span><br><span class="line">03:02.1 Ethernet controller: Intel Corporation XL710/X710 Virtual Function (rev 02)</span><br><span class="line">03:02.2 Ethernet controller: Intel Corporation XL710/X710 Virtual Function (rev 02)</span><br><span class="line">03:02.3 Ethernet controller: Intel Corporation XL710/X710 Virtual Function (rev 02)</span><br><span class="line">03:0a.0 Ethernet controller: Intel Corporation XL710/X710 Virtual Function (rev 02)</span><br><span class="line">03:0a.1 Ethernet controller: Intel Corporation XL710/X710 Virtual Function (rev 02)</span><br><span class="line">03:0a.2 Ethernet controller: Intel Corporation XL710/X710 Virtual Function (rev 02)</span><br><span class="line">03:0a.3 Ethernet controller: Intel Corporation XL710/X710 Virtual Function (rev 02)</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> 4 &gt; /sys/class/net/ens5f0/device/sriov_numvfs</span><br><span class="line"><span class="built_in">echo</span> 4 &gt; /sys/class/net/ens5f1/device/sriov_numvfs</span><br><span class="line">modprobe -r i40evf</span><br><span class="line">ip link <span class="built_in">set</span> ens5f0 vf 0 mac 52:54:00:e8:a5:78</span><br><span class="line">ip link <span class="built_in">set</span> ens5f0 vf 1 mac 52:54:00:e8:a5:79</span><br><span class="line">ip link <span class="built_in">set</span> ens5f0 vf 2 mac 52:54:00:e8:a5:80</span><br><span class="line">ip link <span class="built_in">set</span> ens5f0 vf 3 mac 52:54:00:e8:a5:81</span><br><span class="line">ip link <span class="built_in">set</span> ens5f1 vf 0 mac 52:54:00:e8:a5:82</span><br><span class="line">ip link <span class="built_in">set</span> ens5f1 vf 1 mac 52:54:00:e8:a5:83</span><br><span class="line">ip link <span class="built_in">set</span> ens5f1 vf 2 mac 52:54:00:e8:a5:84</span><br><span class="line">ip link <span class="built_in">set</span> ens5f1 vf 3 mac 52:54:00:e8:a5:85</span><br><span class="line"></span><br><span class="line">$ ip link show ens5f0</span><br><span class="line">19: ens5f0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 9000 qdisc mq state UP mode DEFAULT qlen 1000</span><br><span class="line">    link/ether 0c:c4:7a:88:0c:aa brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    vf 0 MAC 52:54:00:e8:a5:78, spoof checking on, link-state auto, trust off</span><br><span class="line">    vf 1 MAC 52:54:00:e8:a5:79, spoof checking on, link-state auto, trust off</span><br><span class="line">    vf 2 MAC 52:54:00:e8:a5:80, spoof checking on, link-state auto, trust off</span><br><span class="line">    vf 3 MAC 52:54:00:e8:a5:81, spoof checking on, link-state auto, trust off</span><br><span class="line">$ ip link show ens5f1</span><br><span class="line">20: ens5f1: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT qlen 1000</span><br><span class="line">    link/ether 0c:c4:7a:88:0c:ab brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    vf 0 MAC 52:54:00:e8:a5:82, spoof checking on, link-state auto, trust off</span><br><span class="line">    vf 1 MAC 52:54:00:e8:a5:83, spoof checking on, link-state auto, trust off</span><br><span class="line">    vf 2 MAC 52:54:00:e8:a5:84, spoof checking on, link-state auto, trust off</span><br><span class="line">    vf 3 MAC 52:54:00:e8:a5:85, spoof checking on, link-state auto, trust off</span><br></pre></td></tr></table></figure>


    </div>

    
    
    

      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/nic/" rel="tag"><i class="fa fa-tag"></i> nic</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2018/07/08/scsi_dev/" rel="prev" title="scsi device maintain">
      <i class="fa fa-chevron-left"></i> scsi device maintain
    </a></div>
      <div class="post-nav-item">
    <a href="/2018/07/12/benchmark/" rel="next" title="Benchmark">
      Benchmark <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    
  <div class="comments">
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
    </div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#First-question"><span class="nav-number">1.</span> <span class="nav-text">First question</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#What-‘s-the-ring-buffer"><span class="nav-number">1.1.</span> <span class="nav-text">What ‘s the ring buffer</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Linux-network-receive-data-work-flow"><span class="nav-number">1.2.</span> <span class="nav-text">Linux network receive data work flow</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#The-kernel-parameters"><span class="nav-number">1.3.</span> <span class="nav-text">The kernel parameters</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Socket-buffer"><span class="nav-number">1.4.</span> <span class="nav-text">Socket buffer</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#sysctl-w-net-core-netdev-budget-2000"><span class="nav-number">1.4.1.</span> <span class="nav-text">sysctl -w net.core.netdev_budget&#x3D;2000</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#netdev-budget-usecs"><span class="nav-number">1.4.1.1.</span> <span class="nav-text">netdev_budget_usecs</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#netdev-max-backlog"><span class="nav-number">1.4.2.</span> <span class="nav-text">netdev_max_backlog</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Enabling-flow-limits-and-tuning-flow-limit-hash-table-size"><span class="nav-number">1.4.3.</span> <span class="nav-text">Enabling flow limits and tuning flow limit hash table size</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#NIC-Offload"><span class="nav-number">2.</span> <span class="nav-text">NIC Offload</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Generic-Receive-Offloading-replace-Large-receive-offload-https-lwn-net-Articles-358910"><span class="nav-number">2.1.</span> <span class="nav-text">[Generic Receive Offloading replace Large receive offload] (https:&#x2F;&#x2F;lwn.net&#x2F;Articles&#x2F;358910&#x2F;)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#TCP-Segmentation-Offload-TSO"><span class="nav-number">2.2.</span> <span class="nav-text">TCP Segmentation Offload (TSO)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#UDP-Fragmentation-Offload-UFO"><span class="nav-number">2.3.</span> <span class="nav-text">UDP Fragmentation Offload (UFO)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Generic-Segmentation-Offload-GSO"><span class="nav-number">2.4.</span> <span class="nav-text">Generic Segmentation Offload (GSO)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#RECEIVE-SIDE-SCALING-RSS"><span class="nav-number">2.5.</span> <span class="nav-text">RECEIVE-SIDE SCALING (RSS)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Receive-Flow-Steering-ntuple-RFS"><span class="nav-number">2.6.</span> <span class="nav-text">Receive Flow Steering, (ntuple,RFS)</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#intel-82599"><span class="nav-number">2.6.1.</span> <span class="nav-text">intel 82599</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Mellanox-ConnectX-4-Lx"><span class="nav-number">2.6.2.</span> <span class="nav-text">Mellanox ConnectX-4 Lx</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#softnet-stat"><span class="nav-number">2.7.</span> <span class="nav-text">softnet_stat</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#why-telent-return-after-127s"><span class="nav-number">3.</span> <span class="nav-text">why telent return after 127s</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kernel-optimze"><span class="nav-number">4.</span> <span class="nav-text">Kernel optimze</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Enable-VT-D-and-VT-in-BIOS"><span class="nav-number">5.</span> <span class="nav-text">Enable VT-D and VT in BIOS</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#sriov-doc"><span class="nav-number">5.1.</span> <span class="nav-text">sriov doc</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Ginger"
      src="/img/logo-4-blog.png">
  <p class="site-author-name" itemprop="name">Ginger</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">48</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">19</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">56</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ginger</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
      <span class="post-meta-item-text">Symbols count total: </span>
    <span title="Symbols count total">706k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">Reading time total &asymp;</span>
    <span title="Reading time total">10:42</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.6.0
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://b946c5a0bf547c89.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>
<script>
  NexT.utils.loadComments(document.querySelector('#disqus_thread'), () => {
    if (window.DISQUS) {
      DISQUS.reset({
        reload: true,
        config: {page: {
            url: "http://yoursite.com/2018/07/12/nic/",
            identifier: "2018/07/12/nic/",
            title: "linux nic"
          }
        }
      });
    } else {
      var d = document, s = d.createElement('script');
      s.src = 'https://b946c5a0bf547c89.disqus.com/embed.js';
      s.setAttribute('data-timestamp', '' + +new Date());
      (d.head || d.body).appendChild(s);
    }
  });
</script>

</body>
</html>
